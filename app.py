
# Packages
import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from typing import Tuple, List, Dict, Any, Union, Optional
from sklearn.preprocessing import StandardScaler
import shap
import joblib
import os
import gc  # Garbage collection for memory management
import warnings
warnings.filterwarnings('ignore')

# Memory optimization settings
pd.options.mode.chained_assignment = None  # Disable the SettingWithCopyWarning

def get_memory_usage():
    """Retourne l'utilisation m√©moire actuelle en MB."""
    try:
        import psutil
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    except (ImportError, NameError):
        # If psutil is not available, return 0
        return 0

def log_memory_usage(operation_name: str):
    """Log l'utilisation m√©moire pour une op√©ration donn√©e."""
    memory_mb = get_memory_usage()
    if memory_mb > 0:  # Only log if we could get memory usage
        print(f"{operation_name}: {memory_mb:.2f} MB")

def cleanup_memory():
    """Nettoie la m√©moire en for√ßant le garbage collection."""
    gc.collect()
    
    # Pour les DataFrames volumineux, on peut aussi lib√©rer le cache Streamlit si n√©cessaire
    # st.cache_data.clear()  # D√©commenter si besoin de lib√©rer tout le cache

def monitor_memory(func):
    """D√©corateur pour surveiller l'utilisation m√©moire d'une fonction."""
    def wrapper(*args, **kwargs):
        # M√©moire avant
        mem_before = get_memory_usage()
        
        # Ex√©cuter la fonction
        result = func(*args, **kwargs)
        
        # M√©moire apr√®s
        mem_after = get_memory_usage()
        
        # Log la diff√©rence
        diff = mem_after - mem_before
        if diff > 10:  # Log seulement si la diff√©rence est significative (>10 MB)
            print(f"{func.__name__}: +{diff:.2f} MB (total: {mem_after:.2f} MB)")
        
        return result
    return wrapper

def estimate_dataframe_memory(filepath: str, sep: str = ",") -> float:
    """
    Estime l'utilisation m√©moire d'un DataFrame avant de le charger compl√®tement.
    
    Args:
        filepath: Chemin vers le fichier CSV
        sep: S√©parateur de colonnes
        
    Returns:
        Estimation de la m√©moire en MB
    """
    # Lire seulement les 1000 premi√®res lignes pour estimer
    sample = pd.read_csv(filepath, sep=sep, nrows=1000)
    
    # Calculer la m√©moire par ligne
    memory_per_row = sample.memory_usage(deep=True).sum() / len(sample) / 1024 / 1024
    
    # Compter le nombre total de lignes (rapide, ne charge pas le fichier)
    with open(filepath, 'r') as f:
        total_rows = sum(1 for _ in f) - 1  # -1 pour l'en-t√™te
    
    # Estimer la m√©moire totale
    estimated_memory = memory_per_row * total_rows
    
    return estimated_memory

def read_csv_optimized(filepath: str, sep: str = ",", chunksize: int = 10000) -> pd.DataFrame:
    """
    Lit un fichier CSV par chunks pour optimiser la m√©moire.
    
    Args:
        filepath: Chemin vers le fichier CSV
        sep: S√©parateur de colonnes
        chunksize: Taille des chunks
    
    Returns:
        DataFrame complet optimis√©
    """
    chunks = []
    
    # Lire le fichier par chunks
    for chunk in pd.read_csv(filepath, sep=sep, chunksize=chunksize, low_memory=False):
        # Optimiser chaque chunk
        chunk = optimize_dtypes(chunk)
        chunks.append(chunk)
    
    # Concat√©ner tous les chunks
    df = pd.concat(chunks, ignore_index=True)
    
    # Lib√©rer la m√©moire des chunks
    del chunks
    gc.collect()
    
    return df

def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:
    """
    Optimise les types de donn√©es d'un DataFrame pour r√©duire l'utilisation m√©moire.
    
    Args:
        df: DataFrame √† optimiser
    
    Returns:
        DataFrame avec types optimis√©s
    """
    for col in df.columns:
        col_type = df[col].dtype
        
        # Optimisation des entiers
        if col_type != 'object':
            c_min = df[col].min()
            c_max = df[col].max()
            
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            
            # Optimisation des flottants
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        
        # Optimisation des cha√Ænes de caract√®res avec category
        else:
            num_unique_values = len(df[col].unique())
            num_total_values = len(df[col])
            if num_unique_values / num_total_values < 0.5:
                df[col] = df[col].astype('category')
    
    return df

def get_dataset_columns(dataset_name: str) -> Optional[List[str]]:
    """
    Retourne les colonnes importantes pour chaque dataset.
    Permet de charger seulement les colonnes n√©cessaires.
    """
    columns_dict = {
        "accidents": [
            'date', 'heure', 'departement', 'num_commune', 'luminosite', 
            'conditions_atmos', 'type_collision', 'etat_surface', 'an_sem', 'annee',
            'mois', 'jr_sem_q', 'tranche_heure', 'gravite_accident',
            'latitude', 'longitude'
        ],
        # Ajouter d'autres datasets si n√©cessaire
    }
    return columns_dict.get(dataset_name, None)

@st.cache_data
def load_data(dataset_names: Optional[List[str]] = None, optimize_memory: bool = True, use_columns: Optional[Dict[str, List[str]]] = None) -> Dict[str, Union[pd.DataFrame, gpd.GeoDataFrame]]:
    """
    Charge les donn√©es n√©cessaires de mani√®re optimis√©e.
    
    Args:
        dataset_names: Liste des noms de datasets √† charger. Si None, charge tous les datasets.
        optimize_memory: Si True, optimise les types de donn√©es pour r√©duire la m√©moire.
        use_columns: Dict optionnel sp√©cifiant les colonnes √† charger pour chaque dataset.
    
    Returns:
        Un dictionnaire contenant les datasets demand√©s.
    """
    path = "./data/"
    
    # D√©finir tous les datasets disponibles avec optimisation m√©moire
    # Pour les gros fichiers comme accidents, on peut utiliser des chunks
    all_datasets = {
        "X_train": lambda cols=None: pd.read_csv(path + "X_train.csv", low_memory=False, usecols=cols),
        "X_test": lambda cols=None: pd.read_csv(path + "X_test.csv", low_memory=False, usecols=cols),
        "y_train": lambda cols=None: pd.read_csv(path + "y_train.csv", low_memory=False, usecols=cols),
        "y_test": lambda cols=None: pd.read_csv(path + "y_test.csv", low_memory=False, usecols=cols),
        "dep": lambda cols=None: pd.read_csv(path + "departements-france.csv", low_memory=False, usecols=cols),
        "accidents": lambda cols=None: read_csv_optimized(path + "20241031_accidents_Fr_19_22_AH_q.csv", sep=";") if cols is None 
                                      else pd.read_csv(path + "20241031_accidents_Fr_19_22_AH_q.csv", sep=";", usecols=cols, low_memory=False),
        "france": lambda cols=None: gpd.read_file("./communes-20220101-shp/communes-20220101.shp") if cols is None else gpd.read_file("./communes-20220101-shp/communes-20220101.shp")
    }
    
    # Si aucun dataset sp√©cifique n'est demand√©, charger tous les datasets
    if dataset_names is None:
        dataset_names = list(all_datasets.keys())
    
    # Charger uniquement les datasets demand√©s
    result = {}
    for name in dataset_names:
        if name in all_datasets:
            # D√©terminer les colonnes √† charger
            cols = None
            if use_columns and name in use_columns:
                cols = use_columns[name]
            elif optimize_memory and name == "accidents":
                # Utiliser les colonnes par d√©faut pour accidents si optimize_memory est True
                cols = get_dataset_columns("accidents")
            
            # Charger le dataset avec les colonnes sp√©cifi√©es
            df = all_datasets[name](cols)
            
            # Optimiser la m√©moire si demand√© (ne pas optimiser les GeoDataFrames)
            if optimize_memory and isinstance(df, pd.DataFrame) and not isinstance(df, gpd.GeoDataFrame):
                df = optimize_dtypes(df)
            
            result[name] = df
    
    # Force garbage collection apr√®s chargement
    gc.collect()
    
    return result

@st.cache_data
def prepare_dep_accidents(accidents: pd.DataFrame, dep: pd.DataFrame) -> pd.DataFrame:
    """Pr√©pare les donn√©es d'accidents par d√©partement."""
    return accidents.merge(dep, left_on="departement", right_on="code_departement", how="left")

@st.cache_data
def prepare_france_data(_france: gpd.GeoDataFrame, count: pd.DataFrame) -> pd.DataFrame:
    """Pr√©pare les donn√©es g√©ospatiales de la France."""
    france_merged = _france.merge(count, left_on="insee", right_on="num_commune", how="left")
    return france_merged[france_merged['insee'] < '96000']

@st.cache_data
def get_top_communes(_france_data: pd.DataFrame, n: int = 1000) -> pd.DataFrame:
    """R√©cup√®re les N communes avec le plus d'accidents."""
    top_communes = _france_data.nlargest(n, 'count')
    top_communes['count'] = top_communes['count'].round(1)
    return top_communes

@st.cache_data
def prepare_accidents_binaire(_accidents: pd.DataFrame) -> pd.DataFrame:
    """Cr√©e une version binaire des donn√©es d'accidents."""
    accidents_binaire = _accidents.copy()
    value_to_replace = {
        'indemne': '0',
                    'blesse_leger': '1',
                    'blesse_hospitalise': '1',
        'tue': '1'
    }
    accidents_binaire["gravite_accident"] = _accidents['gravite_accident'].replace(value_to_replace)
    return accidents_binaire

@st.cache_data
def prepare_time_series_data(_accidents: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """Pr√©pare les donn√©es pour les analyses temporelles."""
    accidents_dt = _accidents.copy()
    accidents_dt['date'] = pd.to_datetime(accidents_dt['date'], format='%d/%m/%Y', dayfirst=True)
    
    # Utiliser la colonne 'annee' existante au lieu de cr√©er une colonne 'year'
    accidents_dt['year'] = accidents_dt['annee']
    accidents_dt['month'] = accidents_dt['date'].dt.month
    
    # Compter le nombre d'accidents par ann√©e
    accidents_per_year = accidents_dt.groupby('year').size().reset_index()
    accidents_per_year.columns = ['year', 'nombre_accidents']
    
    # Compter le nombre d'accidents par mois et par ann√©e
    monthly_accidents = accidents_dt.groupby(['year', 'month']).size().reset_index()
    monthly_accidents.columns = ['year', 'month', 'nombre_accidents']
    
    # Ajouter les noms des mois
    month_names = ['Janvier', 'F√©vrier', 'Mars', 'Avril', 'Mai', 'Juin', 
                   'Juillet', 'Ao√ªt', 'Septembre', 'Octobre', 'Novembre', 'D√©cembre']
    monthly_accidents['month_name'] = monthly_accidents['month'].apply(lambda x: month_names[x-1])
    
    # Cr√©er la colonne 'sem_ms_an' contenant le num√©ro de la semaine de l'ann√©e
    accidents_dt['sem_ms_an'] = accidents_dt['date'].dt.isocalendar().week
    
    # Grouper par ann√©e et num√©ro de semaine pour compter le nombre d'accidents par semaine
    accidents_per_week = accidents_dt.groupby([accidents_dt['year'], 'sem_ms_an']).size().reset_index()
    accidents_per_week.columns = ['year', 'sem_ms_an', 'accidents_par_sem_an']
    
    return accidents_dt, monthly_accidents, accidents_per_week, accidents_per_year

# Initialisation des donn√©es communes √† toutes les pages
if 'initialized' not in st.session_state:
    # Log m√©moire au d√©marrage
    log_memory_usage("D√©marrage de l'application")
    
    # Chargement minimal des donn√©es au d√©marrage - seulement accidents avec optimisation
    data_dict = load_data(["accidents"], optimize_memory=True)
    accidents = data_dict["accidents"]
    
    # Log m√©moire apr√®s chargement
    log_memory_usage("Apr√®s chargement des accidents")
    
    # Pr√©paration des donn√©es binaires (utilis√©es dans plusieurs pages)
    accidents_binaire = prepare_accidents_binaire(accidents)
    
    # Stockage dans session_state pour √©viter de recharger
    st.session_state.accidents = accidents
    st.session_state.accidents_binaire = accidents_binaire
    st.session_state.initialized = True
    
    # Nettoyage m√©moire apr√®s initialisation
    cleanup_memory()
    log_memory_usage("Apr√®s initialisation et nettoyage")
else:
    # R√©cup√©ration des donn√©es d√©j√† charg√©es
    accidents = st.session_state.accidents
    accidents_binaire = st.session_state.accidents_binaire

######################### Streamlit app #########################

# Afficher l'utilisation m√©moire dans la sidebar (optionnel)
with st.sidebar:
    if st.checkbox("Afficher l'utilisation m√©moire", value=False):
        memory_mb = get_memory_usage()
        st.metric("M√©moire utilis√©e", f"{memory_mb:.1f} MB")
        
        # Bouton pour nettoyer la m√©moire
        if st.button("Nettoyer la m√©moire"):
            cleanup_memory()
            st.success("M√©moire nettoy√©e!")
            st.rerun()

selected = option_menu(
    menu_title=None,
    options=["Introduction", "Exploration", "Visualisation", "Mod√©lisation", "Conclusion", "Chat"],
    icons=["lightbulb", "book", "bar-chart", "gear", "clipboard-data", "chat"],
    orientation="horizontal",
    styles={
        "container": {"padding": "0!important", "background-color": "#f0f2f6"},
        "icon": {"color": "#1E3A8A", "font-size": "12px"},
        "nav-link": {"font-size": "12px", "text-align": "center", "margin":"0px", "padding":"0px 0px 0px 0px", "border-radius": "5px"},
        "nav-link-selected": {"background-color": "#3B82F6"},
    }
)


# Chargement des donn√©es sp√©cifiques √† chaque page
if selected == "Introduction":  # Introduction
    # Ajout d'un style CSS pour am√©liorer l'apparence
    st.markdown("""
    <style>
        .main-title {
            color: #1E3A8A;
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 2px solid #3B82F6;
            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        }
        .title-container {
            background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }
        .intro-header {
            color: #1E3A8A;
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
        }
        .intro-text {
            font-size: 16px;
            line-height: 1.6;
            text-align: justify;
            margin-bottom: 15px;
        }
        .intro-highlight {
            background-color: #F3F4F6;
            border-left: 4px solid #3B82F6;
            padding: 15px;
            margin: 20px 0;
        }
        .intro-source {
            font-size: 14px;
            color: #6B7280;
            font-style: italic;
        }
        .intro-section {
            margin-top: 30px;
            margin-bottom: 30px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre principal am√©lior√© avec conteneur
    st.markdown("""
    <div class="title-container">
        <div class="main-title">Projet Accidents Routiers en France</div>
        <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Analyse des donn√©es d'accidentologie 2019-2022</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Titre de l'introduction
    st.markdown('<div class="intro-header">Contexte et enjeux de la s√©curit√© routi√®re en France</div>', unsafe_allow_html=True)
    
    # Premier paragraphe
    st.markdown("""
    <div class="intro-text">
        Chaque ann√©e en France, plus de 50 000 accidents corporels sont recens√©s par l'Organisation interminist√©riel 
        de la s√©curit√© routi√®re (ONISR), et plus de 1,8 million de constats amiables sont report√©s par les compagnies d'assurance.
        Ces chiffres soulignent l'importance cruciale d'une analyse approfondie des donn√©es d'accidentologie pour am√©liorer 
        la s√©curit√© routi√®re et r√©duire le nombre de victimes sur nos routes.
    </div>
    """, unsafe_allow_html=True)
    
    # Deuxi√®me paragraphe
    st.markdown("""
    <div class="intro-text">
        La mortalit√© routi√®re en France se trouve dans la moyenne europ√©enne selon les √©tudes men√©es par l'Institut national 
        de la statistique et des √©tudes √©conomiques (Insee), comparant les accidents entre les ann√©es 2000 et 2022 des pays 
        membres de l'Union Europ√©enne. Cette position refl√®te les efforts constants d√©ploy√©s par les autorit√©s fran√ßaises, 
        tout en soulignant la n√©cessit√© de poursuivre les actions de pr√©vention.
    </div>
    """, unsafe_allow_html=True)
    
    
    # Troisi√®me paragraphe
    st.markdown("""
    <div class="intro-source">Sources : ONISR, Insee</div>
    """, unsafe_allow_html=True)
    
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    st.markdown('<div class="intro-header">Cr√©ation de la base de donn√©es</div>', unsafe_allow_html=True)
    
    # Ajout d'un style CSS pour am√©liorer l'alignement des images
    st.markdown("""
    <style>
        .image-title {
            text-align: center;
            font-weight: 600;
            color: #1E3A8A;
            font-size: 18px;
            margin-bottom: 18px;
        }
        .image-icon {
            font-size: 15px;
            margin-right: 2px;
            vertical-align: middle;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Utilisation des colonnes Streamlit avec espacement √©gal
    col1, col2, col3 = st.columns([1, 1, 1])
    
    # D√©finition des images, leurs titres et ic√¥nes
    images_data = [
        {
            "title": "Mod√®le de donn√©es",
            "path": "./images/20250313_Mod√®le-Donn√©es_Projet-Accidents.jpg",
            "icon": "üìä"  # Ic√¥ne pour mod√®le de donn√©es
        },
        {
            "title": "Construction de la base de donn√©es",
            "path": "./images/20250313_Construction-BdD_Donn√©es2019-2022.jpg",
            "icon": "üî®"  # Ic√¥ne pour construction
        },
        {
            "title": "Nettoyage et pr√©traitement",
            "path": "./images/20250313_Clean-Preprocess_Features.jpg",
            "icon": "üßπ"  # Ic√¥ne pour nettoyage
        }
    ]
    
    # Affichage des images dans les colonnes
    for col, img_data in zip([col1, col2, col3], images_data):
        with col:
            # Titre avec ic√¥ne
            st.markdown(f'<div class="image-title"><span class="image-icon">{img_data["icon"]}</span>{img_data["title"]}</div>', unsafe_allow_html=True)
            # Affichage de l'image avec une hauteur fixe pour assurer l'alignement
            st.image(img_data["path"], use_column_width=True)
    
    # Ajout d'un espace apr√®s les images
    st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    # Pr√©sentation du projet
    st.markdown("""
    <div class="intro-section">
        <div class="intro-header" style="font-size: 28px;">Objectifs de notre analyse</div>
        <div class="intro-text">
            Ce projet vise √† explorer et analyser les donn√©es d'accidents routiers en France sur la p√©riode 2019-2022 
            pour identifier les facteurs de risque, les tendances temporelles et g√©ographiques, ainsi que les caract√©ristiques 
            des accidents les plus graves. Notre analyse s'appuie sur des visualisations interactives et des mod√®les 
            statistiques pour offrir une compr√©hension approfondie de l'accidentologie routi√®re en France.
        </div>
    </div>
    """, unsafe_allow_html=True)

if selected == "Exploration":  # Exploration    
    
    # Charger les donn√©es d√©partementales si n√©cessaire
    if 'dep' not in st.session_state:
        dep_dict = load_data(["dep"], optimize_memory=True)
        st.session_state.dep = dep_dict["dep"]
    dep = st.session_state.dep
    
    # Ajout d'un style CSS pour am√©liorer l'apparence (m√™me style que l'introduction et la conclusion)
    st.markdown("""
    <style>
        .main-title {
            color: #1E3A8A;
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 2px solid #3B82F6;
            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        }
        .title-container {
            background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }
        .exploration-header {
            color: #1E3A8A;
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre principal am√©lior√© avec conteneur
    st.markdown("""
    <div class="title-container">
        <div class="main-title">Exploration des Donn√©es</div>
        <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Analyse des caract√©ristiques des accidents routiers</div>
    </div>
    """, unsafe_allow_html=True)
    


    # Table des variables du dataset et description
    data = {
        "Variable": ["Num_Acc", "dep", "id_vehicule", "com", "num_veh", "agg", "place", "int", "catu", "atm",
                    "grav", "col", "sexe", "lat", "an_nais", "long", "trajet", "date", "secu1", "secu2",
                    "trch_hor_jr", "locp", "actp", "etatp", "trimestre", "senc", "jr_nuit", "catv", "catr",
                    "obs", "circ", "obsm", "nbv", "choc", "vosp", "manv", "prof", "motor", "pr", "occutc",
                    "pr1", "day", "plan", "month", "surf", "year", "infra", "hrmn", "situ", "lum", "vma"],
        "Descriptif": ["Num√©ro de l'accident", "D√©partement", "Identifiant du v√©hicule (code num√©rique)", "Commune",
                    "Identifiant du v√©hicule (code alphanum√©rique)", "Localisation : hors agglo / en agglo",
                    "Place occup√©e par l'usager", "Intersection", "Cat√©gorie d'usager", "Conditions atmosph√©riques",
                    "Gravit√© de l'accident", "Type de collision", "Sexe de l'usager", "Latitude", "Ann√©e de naissance",
                    "Longitude", "Type de trajet emprunt√©", "Date de l'accident", "Pr√©sence d'un √©quipement de s√©curit√©",
                    "Pr√©sence d'un √©quipement de s√©curit√©", "Tranche horaire de la journ√©e", "Localisation du pi√©ton",
                    "Action du pi√©ton", "Pr√©sence d'autres pi√©tons", "Trimestre", "Sens de circulation",
                    "Distinction jour/nuit", "Cat√©gorie du v√©hicule", "Cat√©gorie de route", "Obstacle fixe heurt√©",
                    "R√©gime de circulation", "Obstacle mobile heurt√©", "Nombre de voies", "Point de choc initial",
                    "Existence d'une voie r√©serv√©e", "Manoeuvre principale avant l'accident", "D√©clivit√© de la route",
                    "Type de motorisation", "Num√©ro du PR", "Nombre d'occupants dans le transport en commun",
                    "Distance en m√®tres du PR", "Jour de l'accident", "Trac√© en plan", "Mois de l'accident",
                    "√âtat de la surface", "Ann√©e de l'accident", "Am√©nagement - infrastructure",
                    "Heure et minutes", "Situation de l'accident", "Conditions d'√©clairage", "Vitesse maximale autoris√©e"]
    }

    # Cr√©ation du DataFrame
    df = pd.DataFrame(data)

    # R√©organiser les colonnes pour un affichage en 4 colonnes
    df_pairs = pd.DataFrame({
        "Variable 1": df["Variable"][::2].reset_index(drop=True),
        "Description 1": df["Descriptif"][::2].reset_index(drop=True),
        "Variable 2": df["Variable"][1::2].reset_index(drop=True),
        "Description 2": df["Descriptif"][1::2].reset_index(drop=True),
    })
    # Style avec CSS
    st.markdown("""
        <style>
            .title {
                color: white;
                background: linear-gradient(to right, #1E3A8A, #3B82F6, #1E3A8A);
                padding: 12px 15px;
                border-radius: 8px;
                text-align: center;
                font-size: 24px;
                font-weight: 600;
                margin-bottom: 20px;
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            }
            .search-box {
                font-size: 18px;
                padding: 10px;
                width: 100%;
                border: 2px solid #3B82F6;
                border-radius: 5px;
                margin-bottom: 20px;
            }
        </style>
    """, unsafe_allow_html=True)

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    # Titre stylis√©
    st.markdown('<div class="title">üìä Description des Variables du Dataset</div>', unsafe_allow_html=True)

    # Champ de recherche
    search_query = st.text_input("üîç Rechercher une variable :", "").lower()

    # Filtrer les r√©sultats
    if search_query:
        df_pairs = df_pairs[df_pairs.apply(lambda row: row.astype(str).str.lower().str.contains(search_query).any(), axis=1)]

    # Accord√©on pour afficher la table
    with st.expander("üìå Voir la table des variables", expanded=True):
        st.dataframe(df_pairs, use_container_width=True)

    # Pr√©paration des donn√©es temporelles si n√©cessaire
    if 'time_series_data' not in st.session_state:
        accidents_dt, monthly_accidents, accidents_per_week, accidents_per_year = prepare_time_series_data(accidents)
        st.session_state.accidents_dt = accidents_dt
        st.session_state.monthly_accidents = monthly_accidents
        st.session_state.accidents_per_week = accidents_per_week
    else:
        accidents_dt = st.session_state.accidents_dt
        monthly_accidents = st.session_state.monthly_accidents
        accidents_per_week = st.session_state.accidents_per_week

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    
    # Graphique interactif du nombre d'accidents par ann√©e
    st.markdown('<div class="title">üìà √âvolution des accidents par ann√©e</div>', unsafe_allow_html=True)
    
    # Compter le nombre d'accidents par ann√©e
    accidents_per_year = accidents_dt.groupby('year').size().reset_index()
    accidents_per_year.columns = ['year', 'nombre_accidents']
    
    # Cr√©er un graphique interactif avec Plotly
    fig_yearly = px.bar(
        accidents_per_year,
        x='year',
        y='nombre_accidents',
        title="Nombre d'accidents par ann√©e (2019-2022)",
        labels={'year': 'Ann√©e', 'nombre_accidents': "Nombre d'accidents"},
        color='nombre_accidents',
        color_continuous_scale='Viridis',
        text='nombre_accidents'
    )
    
    # Personnalisation du graphique
    fig_yearly.update_traces(
        texttemplate='%{text:,}',
        textposition='outside',
        hovertemplate='Ann√©e: %{x}<br>Nombre d\'accidents: %{y:,}'
    )
    
    fig_yearly.update_layout(
        xaxis=dict(tickmode='linear', dtick=1),
        yaxis=dict(title="Nombre d'accidents"),
        coloraxis_showscale=False,
        hoverlabel=dict(bgcolor="white", font_size=12),
        height=500
    )
    
    # Afficher le graphique interactif
    st.plotly_chart(fig_yearly, use_container_width=True)
    
    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            Ce graphique illustre l'√©volution du nombre d'accidents par ann√©e.
            <ul>
              <li>Une <b>baisse notable</b> est observ√©e sur une ann√©e sp√©cifique, possiblement due √† des <b>facteurs externes</b> (ex. confinement COVID-19).</li>
              <li>Les autres ann√©es affichent <b>une relative stabilit√©</b>, n√©cessitant une <b>analyse approfondie des tendances et des mesures de s√©curit√©.</b></li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    # Ajout d'un s√©lecteur pour comparer les donn√©es mensuelles par ann√©e
    st.markdown('<div class="title">üìä Comparaison mensuelle des accidents par ann√©e</div>', unsafe_allow_html=True)
    
    # S√©lection des ann√©es √† afficher
    selected_years = st.multiselect(
        "S√©lectionnez les ann√©es √† comparer",
        options=sorted(monthly_accidents['year'].unique()),
        default=sorted(monthly_accidents['year'].unique())
    )
    
    # Filtrer les donn√©es selon les ann√©es s√©lectionn√©es
    filtered_data = monthly_accidents[monthly_accidents['year'].isin(selected_years)]
    
    # Cr√©er un graphique interactif pour la comparaison mensuelle
    fig_monthly = px.line(
        filtered_data,
        x='month',
        y='nombre_accidents',
        color='year',
        markers=True,
        labels={'month': 'Mois', 'nombre_accidents': "Nombre d'accidents", 'year': 'Ann√©e'},
        title="√âvolution mensuelle des accidents par ann√©e"
    )
    
    # Personnalisation du graphique
    month_names = ['Janvier', 'F√©vrier', 'Mars', 'Avril', 'Mai', 'Juin', 
                   'Juillet', 'Ao√ªt', 'Septembre', 'Octobre', 'Novembre', 'D√©cembre']
    fig_monthly.update_layout(
        xaxis=dict(
            tickmode='array',
            tickvals=list(range(1, 13)),
            ticktext=month_names,
            tickangle=45
        ),
        yaxis=dict(title="Nombre d'accidents"),
        legend=dict(title="Ann√©e"),
        hovermode="x unified",
        height=500
    )
    
    # Afficher le graphique interactif
    st.plotly_chart(fig_monthly, use_container_width=True)
    
    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            Ce graphique repr√©sente l'<b>√©volution mensuelle des accidents </b>sur plusieurs ann√©es.
            <ul>
              <li>Une <b>tendance saisonni√®re </b>est visible, avec des <b>pics r√©currents</b> en certaines p√©riodes de l'ann√©e.</li>
              <li>L'analyse permet d'identifier <b>les p√©riodes √† risque √©lev√©</b>, essentielles pour adapter les <b>politiques de pr√©vention routi√®re.</b></li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    # Tracer la s√©rie chronologique des accidents par semaine
    st.image("./images/output_10_1.png")

    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            Ce graphique illustre l'<b>√©volution hebdomadaire du nombre d'accidents entre 2019 et 2022</b>.
            <ul>
              <li><b>2020 (orange)</b> pr√©sente une <b>forte baisse</b> autour des semaines 10 √† 20, correspondant aux confinements li√©s au COVID-19.</li>
              <li>Les autres ann√©es suivent des tendances similaires, avec des <b>pics d'accidentalit√© en milieu et fin d'ann√©e</b>.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )    

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    # Ajout d'une carte choropl√®the interactive des accidents par d√©partement
    st.markdown('<div class="title">üó∫Ô∏è R√©partition g√©ographique des accidents par d√©partement</div>', unsafe_allow_html=True)
    
    # Pr√©paration des donn√©es pour la carte
    # Compter le nombre d'accidents par d√©partement et par ann√©e
    dep_year_accidents = accidents_dt.groupby(['year', 'departement']).size().reset_index()
    dep_year_accidents.columns = ['year', 'departement', 'nombre_accidents']
    
    # Obtenir les ann√©es disponibles dans les donn√©es
    available_years = sorted(dep_year_accidents['year'].unique())
    
    # S√©lection de l'ann√©e √† afficher sur la carte
    selected_year_map = st.selectbox(
        "S√©lectionnez l'ann√©e √† visualiser sur la carte",
        options=available_years,
        index=len(available_years) - 1  # S√©lectionner la derni√®re ann√©e par d√©faut
    )
    
    # Filtrer les donn√©es pour l'ann√©e s√©lectionn√©e
    filtered_dep_data = dep_year_accidents[dep_year_accidents['year'] == selected_year_map]
    
    # V√©rifier si des donn√©es sont disponibles pour l'ann√©e s√©lectionn√©e
    if len(filtered_dep_data) == 0:
        st.warning(f"Aucune donn√©e disponible pour l'ann√©e {selected_year_map}. Veuillez s√©lectionner une autre ann√©e.")
    else:
        # Convertir les codes de d√©partement pour assurer la compatibilit√© lors de la fusion
        filtered_dep_data = filtered_dep_data.copy()
        filtered_dep_data['departement'] = filtered_dep_data['departement'].astype(str).str.zfill(2)
        
        # Fusionner avec les donn√©es des d√©partements pour obtenir les noms
        filtered_dep_data = filtered_dep_data.merge(dep[['code_departement', 'nom_departement']], 
                                                left_on='departement', 
                                                right_on='code_departement', 
                                                how='left')
        
        # V√©rifier si la fusion a fonctionn√© correctement
        if 'nom_departement' not in filtered_dep_data.columns or filtered_dep_data['nom_departement'].isna().all():
            st.warning(f"Probl√®me lors de la fusion des donn√©es pour l'ann√©e {selected_year_map}. Certaines informations peuvent √™tre manquantes.")
            # Ajouter une colonne nom_departement par d√©faut si elle est manquante
            if 'nom_departement' not in filtered_dep_data.columns:
                filtered_dep_data['nom_departement'] = filtered_dep_data['departement'].astype(str)
            # Remplacer les valeurs NaN par le code du d√©partement
            filtered_dep_data['nom_departement'] = filtered_dep_data['nom_departement'].fillna(filtered_dep_data['departement'].astype(str))
        
        # Cr√©er la carte choropl√®the
        @st.cache_data
        def create_choropleth_map(_filtered_data):
            fig_map = px.choropleth(
                _filtered_data,
                geojson="https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements.geojson",
                locations='departement',
                featureidkey="properties.code",
                color='nombre_accidents',
                color_continuous_scale="Viridis",
                range_color=[0, _filtered_data['nombre_accidents'].max()],
                scope="europe",
                labels={'nombre_accidents': "Nombre d'accidents", 'departement': 'Code d√©partement', 'nom_departement': 'D√©partement'},
                hover_name='nom_departement',
                hover_data={'departement': True, 'nombre_accidents': True, 'nom_departement': True}
            )
            
            fig_map.update_geos(
                fitbounds="locations",
                visible=False,
                resolution=50,
                showcoastlines=True,
                coastlinecolor="RebeccaPurple",
                showland=True,
                landcolor="LightGreen",
                showocean=True,
                oceancolor="LightBlue"
            )
            
            fig_map.update_layout(
                margin={"r": 0, "t": 0, "l": 0, "b": 0},
                height=600,
                geo=dict(
                    center=dict(lon=2.5, lat=46.8),
                    projection_scale=20
                )
            )
            return fig_map
        
        # Afficher la carte
        if len(filtered_dep_data) > 0:
            fig_map = create_choropleth_map(filtered_dep_data)
            st.plotly_chart(fig_map, use_container_width=True)

    # Top 10 des d√©partements avec le plus d'accidents pour l'ann√©e s√©lectionn√©e
    if len(filtered_dep_data) > 0:
        st.markdown(f"#### Top 10 des d√©partements avec le plus d'accidents en {selected_year_map}")
        
        # Trier et s√©lectionner les 10 premiers d√©partements
        top_10_deps = filtered_dep_data.sort_values('nombre_accidents', ascending=False).head(10)
        
        # V√©rifier si des donn√©es sont disponibles pour l'ann√©e s√©lectionn√©e
        if len(top_10_deps) == 0:
            st.warning(f"Aucune donn√©e disponible pour l'ann√©e {selected_year_map}. Veuillez s√©lectionner une autre ann√©e.")
        else:
            # V√©rifier si la colonne nom_departement existe et contient des donn√©es
            if 'nom_departement' not in top_10_deps.columns or top_10_deps['nom_departement'].isna().all():
                # Utiliser le code du d√©partement comme nom si le nom n'est pas disponible
                top_10_deps['nom_departement'] = top_10_deps['departement'].astype(str)
            else:
                # Remplacer les valeurs NaN par le code du d√©partement
                top_10_deps['nom_departement'] = top_10_deps['nom_departement'].fillna(top_10_deps['departement'].astype(str))
            
            # Cr√©er un graphique √† barres horizontales pour le top 10
            @st.cache_data
            def create_top_deps_chart(_top_deps, year):
                fig_top_deps = px.bar(
                    _top_deps,
                    y='nom_departement',
                    x='nombre_accidents',
                    orientation='h',
                    color='nombre_accidents',
                    color_continuous_scale='Viridis',
                    labels={'nombre_accidents': "Nombre d'accidents", 'nom_departement': 'D√©partement'},
                    title=f"Top 10 des d√©partements avec le plus d'accidents en {year}"
                )
                
                fig_top_deps.update_layout(
                    yaxis={'categoryorder': 'total ascending'},
                    height=500
                )
                return fig_top_deps
            
            # Afficher le graphique
            fig_top_deps = create_top_deps_chart(top_10_deps, selected_year_map)
            st.plotly_chart(fig_top_deps, use_container_width=True)
    
    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            Ce graphique pr√©sente le <b>Top 10 des d√©partements les plus accidentog√®nes </b> en 2022.
            <ul>
              <li>Certains d√©partements affichent un <b>nombre significativement √©lev√©</b> d'accidents.</li>
              <li>Ces donn√©es sont essentielles pour <b>cibler les interventions</b> et am√©liorer la <b>s√©curit√© routi√®re</b> dans les zones les plus touch√©es.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    # Chargement des donn√©es n√©cessaires uniquement pour cette page
    if 'france' not in st.session_state:
        # Log m√©moire avant chargement des donn√©es g√©ospatiales
        log_memory_usage("Avant chargement des donn√©es g√©ospatiales")
        
        data_dict = load_data(["france"], optimize_memory=True)
        st.session_state.france = data_dict["france"]
        
        # Log m√©moire apr√®s chargement
        log_memory_usage("Apr√®s chargement des donn√©es g√©ospatiales")
    
    france = st.session_state.france
    
    # Pr√©paration des donn√©es pour l'affichage
    if 'top_1000_communes' not in st.session_state:
        # Nombre d'accident par d√©partement
        count = accidents.groupby("num_commune").size().reset_index()
        count.columns = ["num_commune", "count"]
        
        # Fusionner les donn√©es g√©ospatiales avec les donn√©es d'accidents
        france_data = prepare_france_data(france, count)
        
        # Trier les communes par nombre d'accidents et s√©lectionner les 1000 premi√®res
        top_1000_communes = get_top_communes(france_data, 1000)
        
        st.session_state.top_1000_communes = top_1000_communes
    else:
        top_1000_communes = st.session_state.top_1000_communes

	# Afficher les 1000 communes les plus accidentog√®nes de France
    st.image("./images/output_7_0.png")

        # Afficher le commentaire sous le graphique SEULEMENT
    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            <ul>
              <li>Les <b color="red">zones rouges</b> indiquent une forte concentration d'accidents, principalement dans les grandes villes et les axes routiers majeurs.</li>
              <li>Les <b color="green">zones vertes</b> repr√©sentent des r√©gions moins accidentog√®nes, souvent rurales.</li>
              <li>La carte met en √©vidence les zones critiques n√©cessitant des mesures de pr√©vention renforc√©es.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )

    if st.checkbox("Afficher le top 30"):
        st.dataframe(top_1000_communes[['insee', 'num_commune', 'nom','count']].head(30))
    

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    # Analyse de la gravit√© des accidents par ann√©e
    st.markdown('<div class="title">üö® √âvolution de la gravit√© des accidents par ann√©e</div>', unsafe_allow_html=True)
    
    # Pr√©paration des donn√©es pour l'analyse de gravit√©
    @st.cache_data
    def prepare_gravity_data(_accidents_dt):
        gravity_year = _accidents_dt.groupby(['year', 'gravite_accident']).size().reset_index()
        gravity_year.columns = ['year', 'gravite_accident', 'nombre_accidents']
        
        # Cr√©er un mapping pour les niveaux de gravit√©
        gravity_mapping = {
            'indemne': 'Indemne',
            'blesse_leger': 'Bless√© l√©ger',
            'blesse_hospitalise': 'Bless√© hospitalis√©',
            'tue': 'Tu√©'
        }
        
        # Appliquer le mapping si n√©cessaire
        if 'indemne' in gravity_year['gravite_accident'].values:
            gravity_year['gravite_label'] = gravity_year['gravite_accident'].map(gravity_mapping)
        else:
            # Si les valeurs sont d√©j√† sous forme de libell√©s, les utiliser directement
            gravity_year['gravite_label'] = gravity_year['gravite_accident']
        
        return gravity_year
    
    gravity_year = prepare_gravity_data(accidents_dt)
    
    # Cr√©er un graphique interactif pour l'√©volution de la gravit√©
    @st.cache_data
    def create_gravity_chart(_gravity_data):
        fig_gravity = px.bar(
            _gravity_data,
            x='year',
            y='nombre_accidents',
            color='gravite_label',
            barmode='group',
            labels={'year': 'Ann√©e', 'nombre_accidents': "Nombre d'accidents", 'gravite_label': 'Gravit√©'},
            title="√âvolution de la gravit√© des accidents par ann√©e"
        )
        
        fig_gravity.update_layout(
            xaxis=dict(tickmode='linear', dtick=1),
            yaxis=dict(title="Nombre d'accidents"),
            legend=dict(title="Niveau de gravit√©"),
            height=500
        )
        return fig_gravity
    
    # Afficher le graphique
    fig_gravity = create_gravity_chart(gravity_year)
    st.plotly_chart(fig_gravity, use_container_width=True)

    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Sch√©ma :</b>
            Ce graphique montre l'<b>√©volution de la gravit√© des accidents</b> au fil des ann√©es.
            <ul>
              <li>On observe une <b>stabilit√© des tendances </b>entre les diff√©rentes cat√©gories d'accidents.</li>
              <li>Les accidents <b>graves/mortels</b> restent pr√©occupants et n√©cessitent un <b>suivi approfondi</b> pour identifier les facteurs sous-jacents.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )


    
if selected == "Visualisation":  # DataVisualisation
    
    # Ajout d'un style CSS pour am√©liorer l'apparence (m√™me style que l'introduction et la conclusion)
    st.markdown("""
    <style>
        .main-title {
            color: #1E3A8A;
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 2px solid #3B82F6;
            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        }
        .title-container {
            background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }
        .dataviz-header {
            color: #1E3A8A;
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre principal am√©lior√© avec conteneur
    st.markdown("""
    <div class="title-container">
        <div class="main-title">Visualisation des Donn√©es</div>
        <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Repr√©sentations graphiques des tendances d'accidents</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Fonction pour charger les images de mani√®re optimis√©e
    @st.cache_data
    def load_image(image_index):
        image_paths = {
            0: "./images/output_14_0.png",
            1: "./images/output_15_1.png",
            2: "./images/output_16_0.png",
            3: "./images/output_19_0.png",
            4: "./images/output_21_0.png",
            5: "./images/output_24_0.png",
            6: "./images/output_25_1.png",
            7: "./images/output_26_0.png"
        }
        return image_paths.get(image_index)
    
    num_images = 8
    
    # Utilisation de session_state pour conserver l'√©tat entre les rechargements
    if "image_index" not in st.session_state:
        st.session_state.image_index = 0

    # Sidebar pour slider
    st.sidebar.header("üìä Navigation des Graphes")
    image_index = st.sidebar.slider(
        "S√©lectionnez un graphe", 
        0, 
        num_images - 1, 
        st.session_state.image_index,
        key="image_slider"
    )
    
    # Mettre √† jour l'index dans session_state
    st.session_state.image_index = image_index

    # Affichage de l'image s√©lectionn√©e
    image_path = load_image(image_index)
    if image_path:
        st.image(image_path)
    else:
        st.error("Image non trouv√©e")

    # Boutons de navigation
    col1, col2, col3 = st.columns([1, 2, 1])

    with col1:
        if st.button("‚¨Ö Pr√©c√©dent", key="prev_graph") and st.session_state.image_index > 0:
            st.session_state.image_index -= 1

    with col3:
        if st.button("Suivant ‚û°", key="next_graph") and st.session_state.image_index < num_images - 1:
            st.session_state.image_index += 1

    # Histogramme de la gravit√© des accidents (avec % sur 4 classes et sur classe binaire)
    st.image("./images/output_11_1.png")

    st.markdown(
        """
        <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
            <b>üìå Analyse du Graphique</b>
            Ce graphique en barres montre la distribution des accidents selon leur gravit√©.</b>.
            <ul>
                <li><strong>Indemnes (41.3%) :</strong> Une grande partie des usagers impliqu√©s dans des accidents n'ont subi aucune blessure.</li>
                <li><strong>Bless√©s l√©gers (40.7%) :</strong> Un nombre similaire d'usagers ont subi des blessures mineures.</li>
                <li><strong>Bless√©s hospitalis√©s (15.4%) :</strong> Une part plus faible des victimes n√©cessitent une hospitalisation.</li>
                <li><strong>Tu√©s (2.6%) :</strong> Bien que minoritaire, le nombre de d√©c√®s reste pr√©occupant.</li>
                <li><strong>Interpr√©tation :</strong> La majorit√© des accidents n'entra√Ænent pas de blessures graves, mais la part des bless√©s hospitalis√©s et des d√©c√®s souligne l'importance des mesures de pr√©vention routi√®re.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )


if selected == "Mod√©lisation":  # Mod√©lisation 
    
    # Wrapper try-except pour toute la section de mod√©lisation
    try:
        # V√©rification de la m√©moire disponible au d√©but
        try:
            import psutil
            available_memory = psutil.virtual_memory().available / (1024 * 1024 * 1024)  # GB
            total_memory = psutil.virtual_memory().total / (1024 * 1024 * 1024)  # GB
            memory_percent = psutil.virtual_memory().percent
            
            # Avertir si la m√©moire disponible est faible
            if available_memory < 2:  # Moins de 2GB disponible
                st.warning(f"‚ö†Ô∏è M√©moire disponible faible : {available_memory:.1f} GB sur {total_memory:.1f} GB ({memory_percent:.1f}% utilis√©)")
                st.info("üí° Les donn√©es seront optimis√©es pour r√©duire l'utilisation m√©moire.")
                
                # Si la m√©moire est vraiment critique, proposer de nettoyer le cache
                if available_memory < 1:  # Moins de 1GB disponible
                    if st.button("üßπ Nettoyer le cache pour lib√©rer de la m√©moire"):
                        st.cache_data.clear()
                        cleanup_memory()
                        st.success("‚úÖ Cache nettoy√©. Veuillez rafra√Æchir la page.")
                        st.stop()
        except ImportError:
            pass  # psutil n'est pas install√©, on continue sans v√©rification
        
        # Log m√©moire avant le d√©but de la mod√©lisation
        log_memory_usage("D√©but de la section Mod√©lisation")
    
        # Ajout d'un style CSS pour am√©liorer l'apparence (m√™me style que l'introduction et la conclusion)
        st.markdown("""
        <style>
            .main-title {
                color: #1E3A8A;
                font-size: 36px;
                font-weight: 700;
                text-align: center;
                margin-bottom: 30px;
                padding-bottom: 15px;
                border-bottom: 2px solid #3B82F6;
                text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
            }
            .title-container {
                background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
                padding: 20px;
                border-radius: 10px;
                margin-bottom: 40px;
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
            }
            .model-header {
                color: #1E3A8A;
                font-size: 28px;
                font-weight: 600;
                margin-bottom: 20px;
            }
            .intro-header {
                color: #1E3A8A;
                font-size: 28px;
                font-weight: 600;
                margin-bottom: 20px;
            }
        </style>
        """, unsafe_allow_html=True)
    
        # Titre principal am√©lior√© avec conteneur
        st.markdown("""
        <div class="title-container">
            <div class="main-title">Mod√©lisation Pr√©dictive</div>
            <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Pr√©diction de la gravit√© des accidents</div>
        </div>
        """, unsafe_allow_html=True)
    
        # M√©thodologie

        st.markdown("<div class='intro-header'>La d√©marche m√©thodologique 'en entonnoir'</div>", unsafe_allow_html=True)

        st.markdown("""

        La d√©marche retenue consiste √† partir d'une liste de 8 mod√®les, de les hi√©rarchiser sur la base de leurs performances de bonne classification des observations du jeu de donn√©es de l'ensemble de test.
        Cette d√©marche se d√©cline de la fa√ßon suivante :
        1. Entrainement de 8 mod√®les sans r√©√©quilibrage des modalit√©s de la cible (√† 4 modalit√©s ou binaire). Les mod√®les sont √©valu√©s et hi√©rarchis√©s sur la base de la m√©trique ¬´ F1_score ¬ª de la modalit√© ¬´ positive ¬ª (¬´ tu√© ¬ª dans le cas √† 4 modalit√©s ou ¬´ bless√©_tu√© ¬ª apr√®s binarisation).
        2. Les 4 mod√®les les plus performants ont ensuite √©t√© r√©entra√Æn√©s en r√©√©quilibrant les modalit√©s de la cible (multinomiale ou binaire) : une hi√©rarchisation de leurs performances a √©t√© effectu√©e sur le m√™me principe que ci-dessus.
        3. Nous avons ensuite retenu les 3 mod√®les les plus performants, du point pr√©c√©dent, pour les optimiser √† l'aide de ¬´ GridSearchCV ¬ª et identifi√© les valeurs optimales des hyperparam√®tres de chacun des 3 mod√®les du podium.
        """)

        st.image("./images/20250305_Funnel_Cible-Multi_01.jpg", caption='D√©marche en entonnoir : cible multinomiale')

        st.image("./images/20250305_Funnel_Cible-Binaire_01.jpg", caption='D√©marche en entonnoir : cible binaire')
        st.markdown("""

        Dans ce qui suit, seuls les r√©sultats de mod√©lisation de la cible binaire seront pr√©sent√©s.

        """)

        # Chargement des donn√©es n√©cessaires pour la mod√©lisation si elles ne sont pas d√©j√† charg√©es
        if 'X_train' not in st.session_state:
            try:
                # Log m√©moire avant chargement des donn√©es d'entra√Ænement
                log_memory_usage("Avant chargement des donn√©es d'entra√Ænement")
            
                # Charger les donn√©es avec optimisation m√©moire
                data_dict = load_data(["X_train", "X_test", "y_train", "y_test"], optimize_memory=True)
            
                # V√©rifier si les donn√©es sont charg√©es correctement
                if not all(key in data_dict for key in ["X_train", "X_test", "y_train", "y_test"]):
                    st.error("‚ùå Erreur: Toutes les donn√©es n√©cessaires n'ont pas pu √™tre charg√©es.")
                    st.stop()
            
                # Limiter la taille des datasets pour la mod√©lisation si n√©cessaire
                # Ajuster les limites en fonction de la m√©moire disponible
                try:
                    if 'available_memory' in locals() and available_memory < 4:
                        max_samples_train = 30000  # Limite r√©duite pour l'entra√Ænement
                        max_samples_test = 5000    # Limite r√©duite pour le test
                    else:
                        max_samples_train = 50000  # Limite normale pour l'entra√Ænement
                        max_samples_test = 10000   # Limite normale pour le test
                except:
                    # Valeurs par d√©faut si on ne peut pas d√©terminer la m√©moire
                    max_samples_train = 50000
                    max_samples_test = 10000
            
                # √âchantillonner si les datasets sont trop grands
                if len(data_dict["X_train"]) > max_samples_train:
                    st.info(f"üìä Dataset d'entra√Ænement limit√© √† {max_samples_train} √©chantillons pour optimiser les performances.")
                    sample_indices = np.random.choice(len(data_dict["X_train"]), max_samples_train, replace=False)
                    data_dict["X_train"] = data_dict["X_train"].iloc[sample_indices]
                    data_dict["y_train"] = data_dict["y_train"].iloc[sample_indices]
            
                if len(data_dict["X_test"]) > max_samples_test:
                    st.info(f"üìä Dataset de test limit√© √† {max_samples_test} √©chantillons pour optimiser les performances.")
                    sample_indices = np.random.choice(len(data_dict["X_test"]), max_samples_test, replace=False)
                    data_dict["X_test"] = data_dict["X_test"].iloc[sample_indices]
                    data_dict["y_test"] = data_dict["y_test"].iloc[sample_indices]
            
                # Stocker dans session_state
                st.session_state.X_train = data_dict["X_train"]
                st.session_state.X_test = data_dict["X_test"]
                st.session_state.y_train = data_dict["y_train"]
                st.session_state.y_test = data_dict["y_test"]
            
                # Log m√©moire apr√®s chargement
                log_memory_usage("Apr√®s chargement des donn√©es d'entra√Ænement")
            
                # Nettoyer la m√©moire
                cleanup_memory()
                del data_dict  # Lib√©rer le dictionnaire temporaire
            
                # V√©rifier √† nouveau la m√©moire apr√®s chargement
                memory_after_load = get_memory_usage()
                if memory_after_load > 1000:  # Plus de 1GB utilis√©
                    st.info(f"üìä Utilisation m√©moire apr√®s chargement : {memory_after_load:.0f} MB")
            
            except MemoryError as e:
                st.error("‚ùå Erreur de m√©moire insuffisante lors du chargement des donn√©es.")
                st.info("üí° Suggestions:")
                st.info("‚Ä¢ Fermez d'autres applications pour lib√©rer de la m√©moire")
                st.info("‚Ä¢ Rechargez la page")
                st.info("‚Ä¢ Contactez l'administrateur si le probl√®me persiste")
                st.stop()
            except Exception as e:
                st.error(f"‚ùå Erreur lors du chargement des donn√©es : {str(e)}")
                cleanup_memory()  # Essayer de nettoyer m√™me en cas d'erreur
                st.stop()
    
        # V√©rifier que accidents_binaire est disponible
        if 'accidents_binaire' not in st.session_state:
            st.error("‚ùå Les donn√©es accidents_binaire ne sont pas disponibles. Veuillez d'abord charger les donn√©es depuis la page d'Introduction.")
            st.stop()
    
        accidents_binaire = st.session_state.accidents_binaire
    
        # Cr√©ation d'une nouvelle colonne avec des labels explicites
        try:
            accidents_binaire['gravite_accident_label'] = accidents_binaire['gravite_accident'].replace({
                '0': 'Indemne',
                '1': 'Bless√©/Tu√©'
            })
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la cr√©ation des labels : {str(e)}")
            st.stop()

        # Cr√©ation du graphique
        @st.cache_data
        def create_countplot():
            fig, ax = plt.subplots(figsize=(8, 4))
        
            # Affichage du graphique avec les nouvelles √©tiquettes
            sns.countplot(data=accidents_binaire,
                        x='gravite_accident_label',
                        hue='gravite_accident_label',
                        palette='Blues',
                        order=['Indemne', 'Bless√©/Tu√©'],  # Assure l'ordre souhait√©
                        ax=ax)
            ax.legend().set_visible(False)  # Suppression de la l√©gende

            # Ajout des pourcentages
            total = len(accidents_binaire)
            for p in ax.patches:
                percentage = f"{100 * p.get_height() / total:.1f}%"
                ax.annotate(percentage, 
                            (p.get_x() + p.get_width() / 2, p.get_height()), 
                            ha='center', va='bottom', fontsize=12, color='black')

            # Titre stylis√©
            plt.title("Distribution de la gravit√© des accidents\n",
                    loc="center", fontsize=16, fontweight='bold', color="black")

            plt.xlabel("Gravit√© de l'accident")
            plt.ylabel("Nombre d'accidents")
            return fig
    
        # Afficher le graphique
        fig = create_countplot()
        st.pyplot(fig)
    
        # Afficher le commentaire sous le graphique SEULEMENT
        st.markdown(
            """
            <div style="background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:5px solid #007BFF;">
                <b>üìå Analyse du graphique :</b>  
                Ce graphique illustre la <b>distribution de la gravit√© des accidents</b> en France entre <b>2019 et 2022</b>.  
                On observe une diff√©rence notable entre les accidents <b>l√©gers</b> et ceux <b>graves/mortels</b>,  
                avec une proportion plus importante d'accidents l√©gers. Cette tendance met en √©vidence  
                la n√©cessit√© de renforcer les mesures de s√©curit√© pour r√©duire la s√©v√©rit√© des accidents.
            </div>
            """,
            unsafe_allow_html=True
        )

        # Standardiser les variables 'latitude' et 'longitude' dans X_train et X_test si ce n'est pas d√©j√† fait
        if 'standardized' not in st.session_state:
            scaler = StandardScaler()
            st.session_state.X_train[['latitude', 'longitude']] = scaler.fit_transform(st.session_state.X_train[['latitude', 'longitude']])
            st.session_state.X_test[['latitude', 'longitude']] = scaler.transform(st.session_state.X_test[['latitude', 'longitude']])
            st.session_state.standardized = True

        # Transformer la cible 'gravite_accident' dans y_train et y_test si ce n'est pas d√©j√† fait
        if 'target_transformed' not in st.session_state:
            def transform_target(y):
                return y.replace({
                    'indemne': 'indemne',
                    'blesse_leger': 'blesse_tue',
                    'blesse_hospitalise': 'blesse_tue',
                    'tue': 'blesse_tue'
                })

            st.session_state.y_train = transform_target(st.session_state.y_train)
            st.session_state.y_test = transform_target(st.session_state.y_test)
            st.session_state.target_transformed = True

        # D√©finir le chemin des fichiers
        path = "./models/"

        # Fonction pour charger les mod√®les avec mise en cache
        @st.cache_resource
        def load_model(model_name: Optional[str]) -> Any:
            """
            Charge un mod√®le √† partir d'un fichier pickle avec mise en cache.
        
            Args:
                model_name: Nom du mod√®le √† charger (CatBoost, XGBoost)
            
            Returns:
                Le mod√®le charg√©
            """
            if model_name is None:
                st.error("Le nom du mod√®le ne peut pas √™tre None.")
                return None
            
            model_path = {
                "CatBoost": "20250129_catboost_best_model.pkl",
                "XGBoost": "20250129_xgb_best_model.pkl"
            }
            
            if model_name not in model_path:
                st.error(f"Mod√®le inconnu: {model_name}")
                return None
                
            model_file = os.path.join(path, model_path[model_name])
        
            if os.path.exists(model_file):
                return joblib.load(model_file)
            else:
                st.error(f"Le fichier {model_file} n'existe pas.")
                return None

        # Fonction pour charger les valeurs SHAP avec mise en cache
        @st.cache_resource
        def load_shap_values(model_name: Optional[str]) -> Any:
            """
            Charge les valeurs SHAP pr√©calcul√©es √† partir d'un fichier pickle.
        
            Args:
                model_name: Nom du mod√®le (CatBoost, XGBoost)
            
            Returns:
                Les valeurs SHAP ou None si le fichier n'existe pas
            """
            if model_name is None:
                st.error("Le nom du mod√®le ne peut pas √™tre None.")
                return None
            
            shap_path = {
                "CatBoost": "20250304_catboost_bin_best_shap_values.pkl",
                "XGBoost": "20250304_XGBoost_bin_best_shap_values.pkl"
            }
            
            if model_name not in shap_path:
                st.error(f"Mod√®le inconnu: {model_name}")
                return None
                
            shap_file = os.path.join(path, shap_path[model_name])
        
            if os.path.exists(shap_file):
                return joblib.load(shap_file)
            else:
                st.warning(f"Le fichier de valeurs SHAP {shap_file} n'existe pas. Les valeurs seront calcul√©es √† la vol√©e.")
                return None

        # Fonction pour calculer les valeurs SHAP (avec mise en cache optimis√©e)
        @st.cache_data(ttl=3600, max_entries=5, show_spinner=False)
        def calculate_shap_values(model: Any, X_test: pd.DataFrame, model_name: Optional[str], 
                                 max_samples: int = 1000, memory_limit_mb: int = 500) -> Any:
            """
            Calcule les valeurs SHAP avec mise en cache et optimisation m√©moire.
        
            Args:
                model: Mod√®le charg√©
                X_test: Donn√©es de test
                model_name: Nom du mod√®le
                max_samples: Nombre maximum d'√©chantillons √† traiter (par d√©faut 1000)
                memory_limit_mb: Limite de m√©moire en MB (par d√©faut 500)
            
            Returns:
                Les valeurs SHAP calcul√©es
            """
            if model_name is None:
                st.error("Le nom du mod√®le ne peut pas √™tre None.")
                return None
                
            if model is None:
                st.error("Le mod√®le ne peut pas √™tre None.")
                return None
                
            try:
                # V√©rifier la m√©moire disponible
                initial_memory = get_memory_usage()
                if initial_memory > memory_limit_mb:
                    st.warning(f"‚ö†Ô∏è Utilisation m√©moire √©lev√©e ({initial_memory:.0f} MB). Nettoyage en cours...")
                    cleanup_memory()
                    # Fermer toutes les figures matplotlib ouvertes
                    plt.close('all')
                    # Attendre un peu pour que le GC fasse son travail
                    import time
                    time.sleep(0.5)
            
                # Limiter le nombre d'√©chantillons si n√©cessaire
                n_samples = X_test.shape[0]
                if n_samples > max_samples:
                    st.info(f"üìä √âchantillonnage des donn√©es: {max_samples} exemples sur {n_samples} pour optimiser les performances")
                    X_test = X_test.sample(n=max_samples, random_state=42)
            
                # Afficher une barre de progression
                progress_bar = st.progress(0)
                progress_text = st.empty()
            
                progress_text.text(f"üîÑ Initialisation du calcul SHAP pour {model_name}...")
                progress_bar.progress(10)
            
                # Pour les mod√®les bas√©s sur des arbres (CatBoost, XGBoost, RandomForest)
                try:
                    progress_text.text("üå≥ Tentative avec TreeExplainer (m√©thode rapide)...")
                    progress_bar.progress(30)
                
                    if model_name in ["XGBoost", "CatBoost", "Random Forest"]:
                        explainer = shap.TreeExplainer(model)
                    
                        # Calculer les valeurs SHAP par batch pour √©conomiser la m√©moire
                        batch_size = min(100, len(X_test))
                        shap_values_list = []
                    
                        for i in range(0, len(X_test), batch_size):
                            batch_end = min(i + batch_size, len(X_test))
                            batch = X_test.iloc[i:batch_end]
                        
                            # Mise √† jour de la progression
                            progress = 30 + int(60 * (i + batch_size) / len(X_test))
                            progress_bar.progress(min(progress, 90))
                            progress_text.text(f"üîÑ Calcul en cours... {i+1}-{batch_end}/{len(X_test)} exemples")
                        
                            # Calculer les valeurs SHAP pour ce batch
                            batch_shap_values = explainer.shap_values(batch)
                            shap_values_list.append(batch_shap_values)
                        
                            # V√©rifier la m√©moire apr√®s chaque batch
                            current_memory = get_memory_usage()
                            if current_memory > memory_limit_mb * 0.8:
                                st.warning(f"‚ö†Ô∏è M√©moire proche de la limite ({current_memory:.0f} MB). Nettoyage...")
                                cleanup_memory()
                                # Si toujours trop √©lev√©, r√©duire la taille du prochain batch
                                if current_memory > memory_limit_mb * 0.9:
                                    batch_size = max(10, batch_size // 2)
                    
                        # Concat√©ner tous les r√©sultats
                        if isinstance(shap_values_list[0], list):
                            # Pour les mod√®les multi-classes
                            shap_values = [np.vstack([batch[i] for batch in shap_values_list]) 
                                         for i in range(len(shap_values_list[0]))]
                        else:
                            shap_values = np.vstack(shap_values_list)
                    
                        progress_bar.progress(100)
                        progress_text.text("‚úÖ Calcul SHAP termin√© avec succ√®s!")
                        return shap_values
                    
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è TreeExplainer non disponible: {str(e)}")
                
                # Essayer avec l'explainer standard
                try:
                    progress_text.text("üîß Tentative avec Explainer standard...")
                    progress_bar.progress(40)
                
                    explainer = shap.Explainer(model)
                    shap_values = explainer(X_test)
                
                    progress_bar.progress(100)
                    progress_text.text("‚úÖ Calcul SHAP termin√© avec succ√®s!")
                    return shap_values
                
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Explainer standard non disponible: {str(e)}")
                
                    # M√©thode de fallback avec KernelExplainer (plus lente mais plus robuste)
                    progress_text.text("üî¨ Utilisation de KernelExplainer (m√©thode alternative)...")
                    progress_bar.progress(50)
                
                    try:
                        # R√©duire encore plus l'√©chantillon pour KernelExplainer
                        kernel_sample_size = min(100, X_test.shape[0])
                        X_sample = X_test.sample(kernel_sample_size, random_state=42) if X_test.shape[0] > kernel_sample_size else X_test
                    
                        # Cr√©er un background dataset plus petit
                        background_size = min(50, kernel_sample_size)
                        background = shap.sample(X_sample, background_size)
                    
                        # Cr√©er l'explainer
                        if hasattr(model, 'predict_proba'):
                            kernel_explainer = shap.KernelExplainer(model.predict_proba, background)
                        else:
                            kernel_explainer = shap.KernelExplainer(model.predict, background)
                    
                        # Calculer les valeurs SHAP
                        progress_text.text(f"üîÑ Calcul SHAP sur {kernel_sample_size} √©chantillons...")
                        progress_bar.progress(70)
                    
                        shap_values = kernel_explainer.shap_values(X_sample)
                    
                        progress_bar.progress(100)
                        progress_text.text("‚úÖ Calcul SHAP termin√© (m√©thode alternative)!")
                    
                        # Nettoyer la m√©moire apr√®s le calcul
                        cleanup_memory()
                    
                        return shap_values
                    
                    except Exception as e2:
                        st.error(f"‚ùå Toutes les m√©thodes ont √©chou√©: {str(e2)}")
                        progress_bar.empty()
                        progress_text.empty()
                    
                        # Cr√©er des valeurs SHAP factices pour √©viter les erreurs
                        st.warning("‚ö†Ô∏è Utilisation de valeurs approximatives pour la visualisation")
                        dummy_values = np.random.normal(0, 0.01, (X_test.shape[0], X_test.shape[1]))
                        return dummy_values
        
            except MemoryError:
                st.error("‚ùå Erreur de m√©moire insuffisante. R√©duction automatique de la taille des donn√©es...")
                if 'progress_bar' in locals():
                    progress_bar.empty()
                if 'progress_text' in locals():
                    progress_text.empty()
            
                # Nettoyer agressivement la m√©moire
                cleanup_memory()
                plt.close('all')
            
                # R√©essayer avec un √©chantillon beaucoup plus petit
                reduced_size = min(50, X_test.shape[0])
                X_reduced = X_test.sample(reduced_size, random_state=42)
            
                # Appel r√©cursif avec des param√®tres plus restrictifs
                return calculate_shap_values(model, X_reduced, model_name, 
                                           max_samples=reduced_size, 
                                           memory_limit_mb=memory_limit_mb * 2)  # Augmenter la limite pour √©viter une boucle infinie
            
            except Exception as e:
                st.error(f"‚ùå Erreur g√©n√©rale lors du calcul des valeurs SHAP: {str(e)}")
                progress_bar.empty()
                progress_text.empty()
            
                # Retourner des valeurs factices pour √©viter les erreurs
                dummy_values = np.zeros((min(100, len(X_test)), len(X_test.columns)))
                return dummy_values
        
            finally:
                # Nettoyer les √©l√©ments de progression
                if 'progress_bar' in locals():
                    progress_bar.empty()
                if 'progress_text' in locals():
                    progress_text.empty()
            
                # Forcer le nettoyage m√©moire
                cleanup_memory()

        # Fonction pour extraire directement les importances du mod√®le Random Forest
        def get_feature_importances_rf(model, feature_names):
            """
            Extrait les importances directement du mod√®le Random Forest.
        
            Args:
                model: Mod√®le Random Forest
                feature_names: Noms des features
            
            Returns:
                DataFrame avec les importances tri√©es
            """
            if not hasattr(model, 'feature_importances_'):
                st.error("Le mod√®le ne poss√®de pas d'attribut feature_importances_")
                return None
        
            # Extraire les importances
            importances = model.feature_importances_
        
            # V√©rifier que les dimensions correspondent
            if len(importances) != len(feature_names):
                st.warning(f"Dimensions incorrectes: importances {len(importances)} vs features {len(feature_names)}")
                # Ajuster si n√©cessaire
                if len(importances) < len(feature_names):
                    # Compl√©ter avec des z√©ros
                    importances = np.pad(importances, (0, len(feature_names) - len(importances)))
                else:
                    # Tronquer
                    importances = importances[:len(feature_names)]
        
            # Cr√©er un DataFrame
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': importances
            })
        
            # Trier par importance d√©croissante
            importance_df = importance_df.sort_values('Importance', ascending=False)
        
            return importance_df

        # Fonction pour cr√©er les graphiques SHAP avec mise en cache
        @st.cache_data
        def create_importance_plot_rf(_shap_values_data, _feature_names, max_display=24, min_display=10):
            """Cr√©e un graphique d'importance des variables sp√©cifiquement pour Random Forest."""
            fig = plt.figure(figsize=(12, 8))  # Augmenter la taille pour plus de lisibilit√©
            try:
                # Convertir _feature_names en tableau NumPy
                feature_names_array = np.array(_feature_names)
            
                # Pour Random Forest, nous utilisons une approche manuelle plus robuste
                # Extraire les valeurs SHAP pour la classe positive (indice 1 pour classification binaire)
                if len(_shap_values_data) > 1:  # S'il y a plusieurs classes
                    shap_values_to_use = _shap_values_data[1]  # Utiliser la classe positive
                else:
                    shap_values_to_use = _shap_values_data[0]
            
                # Calculer l'importance des features (moyenne des valeurs absolues)
                feature_importance = np.abs(shap_values_to_use).mean(0)
            
                # Cr√©er un DataFrame pour le tri et l'affichage
                importance_df = pd.DataFrame({
                    'Feature': feature_names_array,
                    'Importance': feature_importance
                })
            
                # Trier par importance d√©croissante
                importance_df = importance_df.sort_values('Importance', ascending=False)
            
                # Limiter aux max_display plus importantes features
                top_features = importance_df.head(max_display)
            
                # S'assurer d'avoir au moins min_display features
                if len(top_features) < min_display and len(importance_df) >= min_display:
                    top_features = importance_df.head(min_display)
            
                # Cr√©er une palette de couleurs d√©grad√©es
                from matplotlib import cm
                colors = cm.get_cmap('viridis')(np.linspace(0, 0.8, len(top_features)))
            
                # Cr√©er un graphique √† barres horizontal avec des couleurs d√©grad√©es
                bars = plt.barh(
                    y=top_features['Feature'],
                    width=top_features['Importance'],
                    color=colors
                )
            
                # Ajouter les valeurs √† c√¥t√© des barres
                for bar in bars:
                    width = bar.get_width()
                    plt.text(width + width*0.01,  # Position l√©g√®rement √† droite de la barre
                            bar.get_y() + bar.get_height()/2,  # Position verticale centr√©e
                            f'{width:.4f}',  # Formater avec 4 d√©cimales
                            ha='left', va='center',
                            fontsize=9)
            
                # Inverser l'axe y pour avoir la feature la plus importante en haut
                plt.gca().invert_yaxis()
            
                # Ajouter une grille horizontale pour faciliter la lecture
                plt.grid(axis='x', linestyle='--', alpha=0.6)
            
                # Ajouter le titre et les labels
                plt.title("Importance des features (Random Forest)",
                        fontsize=20,
                        fontstyle='italic')
                plt.xlabel("Impact moyen sur la pr√©diction (valeur SHAP)")
            
                # Ajuster les marges
                plt.tight_layout()
            
                return fig
            except Exception as e:
                st.error(f"Erreur d'affichage RF: {str(e)}")
                # Cr√©er un graphique d'erreur
                plt.text(0.5, 0.5, f"Erreur d'affichage RF: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
            
                plt.title("Importance des features (Random Forest) - ERREUR",
                        fontsize=20,
                        fontstyle='italic',
                        color='red')
                plt.tight_layout()
                return fig
    
        @st.cache_data
        def create_importance_plot(_shap_values_data, _feature_names, max_display=24):
            """Cr√©e un graphique d'importance des variables pour les mod√®les."""
            fig = plt.figure(figsize=(10, 6))
            try:
                # Convertir _feature_names en tableau NumPy pour √©viter les probl√®mes d'indexation
                feature_names_array = np.array(_feature_names)
            
                # Pour les mod√®les
                shap.summary_plot(_shap_values_data, 
                                plot_type="bar", 
                                color='#39c5f2',
                                max_display=max_display,
                                feature_names=feature_names_array,
                                show=False)
            except Exception as e:
                plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
            
            plt.title("Importance des features dans la construction du mod√®le",
                    fontsize=20,
                    fontstyle='italic')
            plt.tight_layout()
            return fig
    
        @st.cache_data
        def create_beeswarm_plot_rf(_shap_values_data, _feature_names, max_display=24):
            """Cr√©e un graphique BeeSwarm sp√©cifiquement pour Random Forest."""
            fig = plt.figure(figsize=(14, 8))
            try:
                # Convertir feature_names en array numpy
                feature_names_array = np.array(_feature_names)
            
                # Pour Random Forest, nous devons traiter les valeurs SHAP diff√©remment
                # Extraire les valeurs SHAP pour la classe positive (indice 1 pour classification binaire)
                if len(_shap_values_data) > 1:  # S'il y a plusieurs classes
                    shap_values_to_use = _shap_values_data[1]  # Utiliser la classe positive
                else:
                    shap_values_to_use = _shap_values_data[0]
            
                # Calculer l'importance des features (moyenne des valeurs absolues)
                feature_importance = np.abs(shap_values_to_use).mean(0)
            
                # Trier les indices par importance
                sort_inds = np.argsort(feature_importance)
            
                # Limiter aux max_display plus importantes features
                if sort_inds.size > max_display:
                    sort_inds = sort_inds[-max_display:]
            
                # Cr√©er un DataFrame pour le plot
                X_test_values = st.session_state.X_test.values
            
                # Cr√©er un scatter plot pour chaque feature
                for i, ind in enumerate(sort_inds):
                    # Position verticale (feature)
                    pos = len(sort_inds) - i - 1
                
                    # Valeurs SHAP pour cette feature
                    shap_values_feature = shap_values_to_use[:, ind]
                
                    # Valeurs de la feature
                    feature_values = X_test_values[:, ind]
                
                    # Normaliser les valeurs de la feature pour la couleur
                    if np.max(feature_values) - np.min(feature_values) > 0:
                        normalized_values = (feature_values - np.min(feature_values)) / (np.max(feature_values) - np.min(feature_values))
                    else:
                        normalized_values = np.zeros_like(feature_values)
                
                    # Cr√©er un scatter plot
                    plt.scatter(
                        shap_values_feature,
                        np.ones(len(shap_values_feature)) * pos,
                        c=normalized_values,
                        cmap='coolwarm',
                        alpha=0.8,
                        s=20
                    )
            
                # Ajouter les noms des features
                plt.yticks(range(len(sort_inds)), [feature_names_array[ind] for ind in sort_inds])
            
                # Ajouter une grille horizontale
                plt.grid(axis='x', linestyle='--', alpha=0.6)
            
                # Ajouter le titre et les labels
                plt.title("Impact des features sur la pr√©diction (Random Forest)",
                        fontsize=20,
                        fontstyle='italic')
                plt.xlabel("Impact sur la pr√©diction (valeur SHAP)")
            
                # Ajouter une barre de couleur
                cbar = plt.colorbar()
                cbar.set_label("Valeur de la feature (normalis√©e)")
            
                # Ajuster les marges
                plt.tight_layout()
            
                return fig
            except Exception as e:
                st.error(f"Erreur d'affichage RF: {str(e)}")
                # Cr√©er un graphique d'erreur
                plt.text(0.5, 0.5, f"Erreur d'affichage RF: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
            
                plt.title("BeeSwarm Plot (Random Forest) - ERREUR",
                        fontsize=20,
                        fontstyle='italic',
                        color='red')
                plt.tight_layout()
                return fig
    
        @st.cache_data
        def create_beeswarm_plot(_shap_values_data, _feature_names, max_display=24):
            """Cr√©e un graphique BeeSwarm."""
            fig = plt.figure(figsize=(14, 8))
            try:
                # Convertir feature_names en array numpy pour √©viter les probl√®mes d'indexation
                feature_names_array = np.array(_feature_names)
            
                # Pour les mod√®les autres que Random Forest
                shap.summary_plot(
                    _shap_values_data,
                    st.session_state.X_test,
                    plot_type="dot",
                    max_display=max_display,
                    feature_names=feature_names_array,
                    show=False
                )
            except Exception as e:
                st.error(f"Erreur lors de l'affichage du BeeSwarm plot: {str(e)}")
                st.info("Tentative avec une m√©thode alternative...")
                try:
                    # M√©thode alternative plus simple
                    shap.summary_plot(
                        _shap_values_data,
                        st.session_state.X_test.values,
                        plot_type="dot",
                        feature_names=_feature_names,
                        max_display=max_display,
                        show=False
                    )
                except Exception as e2:
                    st.error(f"L'affichage alternatif a √©galement √©chou√©: {str(e2)}")
                    # M√©thode de secours ultime - cr√©er un graphique simple
                    try:
                        plt.figure(figsize=(14, 8))
                        # Cr√©er un DataFrame pour visualiser les valeurs SHAP moyennes
                        mean_shap = np.abs(_shap_values_data).mean(0) if hasattr(_shap_values_data, 'mean') else np.abs(_shap_values_data.values).mean(0)
                    
                        shap_df = pd.DataFrame({
                            'Feature': _feature_names,
                            'SHAP Value': mean_shap
                        })
                    
                        # Trier par valeur absolue
                        shap_df = shap_df.sort_values('SHAP Value', ascending=False).head(max_display)
                    
                        # Cr√©er un barplot
                        plt.barh(y=shap_df['Feature'], width=shap_df['SHAP Value'], color='#39c5f2')
                        plt.title("Importance des features (m√©thode de secours)", fontsize=14)
                        plt.xlabel("Impact moyen sur la pr√©diction (valeur SHAP)")
                    except Exception as e3:
                        plt.text(0.5, 0.5, f"Toutes les m√©thodes d'affichage ont √©chou√©: {str(e3)}", 
                                horizontalalignment='center', verticalalignment='center',
                                transform=plt.gca().transAxes)
        
            # Ajuster la taille des √©tiquettes et l'apparence g√©n√©rale
            ax = plt.gca()
            # R√©duire la taille de la police des √©tiquettes des variables
            ax.tick_params(axis='y', labelsize=9)
            # Augmenter la taille de la police des valeurs sur l'axe x
            ax.tick_params(axis='x', labelsize=10)
        
            # Ajuster les marges pour √©viter que les √©tiquettes ne soient coup√©es
            plt.subplots_adjust(left=0.25, right=0.95, top=0.95, bottom=0.1)
        
            plt.title("Interpr√©tation Globale BeeSwarm", 
                    fontsize=14, fontstyle='italic', fontweight='bold')
            plt.tight_layout()
            return fig
    
        @st.cache_data
        def create_dependence_plot(_shap_values_data, _X_test_data, feature, _feature_names):
            """Cr√©e un graphique de d√©pendance."""
            fig = plt.figure(figsize=(10, 6))
            try:
                # Convertir _feature_names en tableau NumPy pour √©viter les probl√®mes d'indexation
                feature_names_array = np.array(_feature_names)
            
                # Convertir _X_test_data en tableau NumPy
                X_test_array = _X_test_data.values
            
                # Pour les mod√®les
                shap.dependence_plot(feature, 
                                    _shap_values_data, 
                                    X_test_array, 
                                    interaction_index=None, 
                                    alpha=0.5,
                                    feature_names=feature_names_array,
                                    ax=plt.gca(),
                                    show=False)
            except Exception as e:
                plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
            
            plt.title("Graphique de d√©pendance",
                    fontsize=11,
                    fontstyle='italic')
            plt.tight_layout()
            return fig
    
        @st.cache_data
        def create_dependence_interaction_plot(_shap_values_data, _X_test_data, feature, interaction_feature, _feature_names):
            """Cr√©e un graphique de d√©pendance avec interaction."""
            fig = plt.figure(figsize=(10, 6))
            try:
                # Convertir _feature_names en tableau NumPy pour √©viter les probl√®mes d'indexation
                feature_names_array = np.array(_feature_names)
            
                # Convertir _X_test_data en tableau NumPy
                X_test_array = _X_test_data.values
            
                # Pour les mod√®les
                shap.dependence_plot(feature, 
                                    _shap_values_data, 
                                    X_test_array, 
                                    interaction_index=interaction_feature, 
                                    alpha=0.5,
                                    feature_names=feature_names_array,
                                    ax=plt.gca(),
                                    show=False)
            except Exception as e:
                plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
            
            plt.title("Graphique de d√©pendance et interaction",
                    fontsize=11,
                    fontstyle='italic')
            plt.tight_layout()
            return fig
    
        @st.cache_data
        def create_waterfall_plot(_shap_values_data, observation_index):
            """Cr√©e un graphique Waterfall."""
            fig = plt.figure(figsize=(10, 6))
            try:
                # Essayer d'utiliser la nouvelle API
                if isinstance(_shap_values_data, list):
                    # Pour les mod√®les avec structure de liste
                    try:
                        # V√©rifier que l'index d'observation est valide
                        if observation_index >= len(_shap_values_data[0]):
                            observation_index = 0
                        
                        # V√©rifier les dimensions
                        shap_values_to_plot = _shap_values_data[0][observation_index]
                    
                        # Utiliser la nouvelle API
                        shap.plots.waterfall(shap_values_to_plot, show=False)
                    except Exception as e:
                        # Fallback sur l'ancienne API
                        plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                                horizontalalignment='center', verticalalignment='center',
                                transform=plt.gca().transAxes)
                else:
                    # Pour les mod√®les avec structure simple
                    try:
                        # Utiliser la nouvelle API
                        shap.plots.waterfall(_shap_values_data[observation_index], show=False)
                    except Exception as e:
                        # Fallback sur l'ancienne API
                        plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                                horizontalalignment='center', verticalalignment='center',
                                transform=plt.gca().transAxes)
                    
                        plt.xlabel("Impact sur la pr√©diction (valeur SHAP)")
            except Exception as e:
                plt.text(0.5, 0.5, f"Erreur d'affichage: {str(e)}", 
                        horizontalalignment='center', verticalalignment='center',
                        transform=plt.gca().transAxes)
        
            plt.title("Waterfall Plot", fontsize=11, fontstyle='italic')
            plt.tight_layout()
            return fig

        # Menu pour charger le fichier pickle du mod√®le choisi
        model_choice = st.selectbox("Choisissez un mod√®le", ["CatBoost", "XGBoost"])
    
        # Charger le mod√®le choisi avec gestion d'erreur
        try:
            model = load_model(model_choice)
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du mod√®le {model_choice} : {str(e)}")
            model = None
    
        if model is not None:
            st.write(f"‚úÖ Mod√®le {model_choice} charg√© avec succ√®s.")
        
            try:
                # Charger ou calculer les valeurs SHAP
                shap_values = load_shap_values(model_choice)
                if shap_values is None:
                    with st.spinner(f"‚è≥ Calcul des valeurs SHAP pour le mod√®le {model_choice}..."):
                        # Limiter le nombre d'√©chantillons pour SHAP si n√©cessaire
                        max_shap_samples = 1000
                        X_test_for_shap = st.session_state.X_test
                        if len(X_test_for_shap) > max_shap_samples:
                            st.info(f"üìä Utilisation de {max_shap_samples} √©chantillons pour le calcul SHAP (sur {len(X_test_for_shap)} disponibles)")
                            X_test_for_shap = X_test_for_shap.sample(n=max_shap_samples, random_state=42)
                    
                        shap_values = calculate_shap_values(model, X_test_for_shap, model_choice)
            
                # Cr√©er l'explainer une seule fois
                explainer = shap.Explainer(model)
            
            except Exception as e:
                st.error(f"‚ùå Erreur lors du calcul des valeurs SHAP : {str(e)}")
                shap_values = None
                explainer = None
        
            # S√©lectionner une valeur pour chaque feature de X_test
            st.markdown("<div class='intro-header'>S√©lection des valeurs des features</div>", unsafe_allow_html=True)
        
            # Option pour afficher toutes les variables ou seulement les plus importantes
            show_all_features = st.checkbox("Afficher toutes les variables", value=False)
        
            # D√©finir les features √† afficher
            if show_all_features:
                features_to_display = st.session_state.X_test.columns.tolist()
            else:
                # Utiliser un nombre limit√© de features pour l'interface utilisateur
                features_to_display = ["catv", "place", "obsm", "choc", "manv", "col"]
        
            # Cr√©er un conteneur pour les s√©lecteurs avec d√©filement si n√©cessaire
            feature_container = st.container()
        
            # Utiliser des colonnes pour organiser les s√©lecteurs (3 colonnes)
            if show_all_features:
                # Avec beaucoup de variables, utiliser un layout plus compact
                num_cols = 3
                cols = feature_container.columns(num_cols)
            
                feature_values = {}
                for i, feature in enumerate(features_to_display):
                    col_idx = i % num_cols
                    with cols[col_idx]:
                        feature_values[feature] = st.selectbox(
                            f"{feature}", 
                            list(st.session_state.X_test[feature].unique()),
                            key=f"feature_{feature}"
                        )
            else:
                # Avec peu de variables, utiliser un layout plus spacieux
                feature_values = {}
                for feature in features_to_display:
                    if feature in st.session_state.X_test.columns:
                        feature_values[feature] = st.selectbox(
                            f"Valeur pour {feature}", 
                            list(st.session_state.X_test[feature].unique()),
                            key=f"feature_{feature}"
                        )
        
            # Compl√©ter avec les valeurs par d√©faut pour les autres features
            for feature in st.session_state.X_test.columns:
                if feature not in feature_values:
                    feature_values[feature] = st.session_state.X_test[feature].iloc[0]
        
            # Afficher la valeur pr√©dite de 'gravite_accident'
            predict_button = st.button("Pr√©dire la gravit√© de l'accident")
        
            if predict_button:
                selected_features = pd.DataFrame([feature_values])
                predicted_value = model.predict(selected_features)
            
                # Convertir la valeur num√©rique en libell√©
                prediction_label = "Indemne" if predicted_value[0] == 0 else "Bless√© ou Tu√©"
                prediction_color = "#3B82F6" if predicted_value[0] == 0 else "#EF4444"
            
                # Afficher le r√©sultat avec un style am√©lior√©
                st.markdown(f"""
                <div style="background-color: #f0f7ff; padding: 15px; border-radius: 10px; border-left: 5px solid {prediction_color};">
                    <h4 style="margin-top: 0;">Pr√©diction</h4>
                    <p style="font-size: 18px; font-weight: bold;">{predicted_value[0]} : {prediction_label}</p>
                </div>
                """, unsafe_allow_html=True)
        
            # Menu pour afficher les graphiques d'interpr√©tabilit√© (SHAP)
            st.markdown("<div class='intro-header'>Interpr√©tabilit√© globale du mod√®le</div>", unsafe_allow_html=True)
        
            # V√©rifier que les valeurs SHAP sont disponibles
            if shap_values is not None:
                shap_choice = st.selectbox("Choisissez un graphique d'interpr√©tabilit√©", 
                                          ["Importance des variables", "BeeSwarm", "D√©pendance", "D√©pendance et interaction"])
            
                # Pr√©parer les donn√©es pour les graphiques SHAP
                feature_names = st.session_state.X_test.columns.tolist()
                X_test_values = st.session_state.X_test.values
            
                # Afficher les graphiques d'interpr√©tabilit√© globale
                if shap_choice == "Importance des variables":
                    with st.spinner("G√©n√©ration du graphique d'importance des variables..."):
                        try:
                            # Utiliser la fonction pour CatBoost et XGBoost
                            fig = create_importance_plot(shap_values, feature_names, max_display=24)
                            st.pyplot(fig)
                            plt.close()
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de la g√©n√©ration du graphique d'importance : {str(e)}")
                            plt.close()  # S'assurer que la figure est ferm√©e
        
                elif shap_choice == "BeeSwarm":
                    with st.spinner("G√©n√©ration du graphique BeeSwarm..."):
                        try:
                            # Utiliser la fonction pour CatBoost et XGBoost
                            fig = create_beeswarm_plot(shap_values, feature_names, max_display=24)
                            st.pyplot(fig)
                            plt.close()
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de la g√©n√©ration du graphique BeeSwarm : {str(e)}")
                            plt.close()  # S'assurer que la figure est ferm√©e
        
                elif shap_choice == "D√©pendance":
                    feature = st.selectbox("Choisissez une feature", feature_names)
                    with st.spinner(f"G√©n√©ration du graphique de d√©pendance pour {feature}..."):
                        try:
                            # Cr√©er une nouvelle figure pour √©viter les probl√®mes de mise en cache
                            plt.figure(figsize=(10, 6))
                        
                            # Pour les mod√®les CatBoost et XGBoost
                            shap.dependence_plot(feature, 
                                                shap_values, 
                                                st.session_state.X_test,
                                                interaction_index=None, 
                                                alpha=0.5,
                                                feature_names=feature_names,
                                                ax=plt.gca(),
                                                show=False)
                        
                            plt.title("Graphique de d√©pendance",
                                    fontsize=11,
                                    fontstyle='italic')
                            plt.tight_layout()
                            st.pyplot(plt.gcf())
                            plt.close()
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de la g√©n√©ration du graphique de d√©pendance : {str(e)}")
                            plt.close()  # S'assurer que la figure est ferm√©e
            
                elif shap_choice == "D√©pendance et interaction":
                    feature = st.selectbox("Choisissez une feature", feature_names, key="dep_feature")
                    interaction_feature = st.selectbox("Choisissez une feature d'interaction", 
                                                      feature_names, key="int_feature")
                    with st.spinner(f"G√©n√©ration du graphique de d√©pendance et interaction pour {feature} et {interaction_feature}..."):
                        try:
                            # Cr√©er une nouvelle figure pour √©viter les probl√®mes de mise en cache
                            plt.figure(figsize=(10, 6))
                        
                            # Pour les mod√®les CatBoost et XGBoost
                            shap.dependence_plot(feature, 
                                                shap_values, 
                                                st.session_state.X_test, 
                                                interaction_index=interaction_feature, 
                                                alpha=0.5,
                                                feature_names=feature_names,
                                                ax=plt.gca(),
                                                show=False)
                        
                            plt.title("Graphique de d√©pendance et interaction",
                                    fontsize=11,
                                    fontstyle='italic')
                            plt.tight_layout()
                            st.pyplot(plt.gcf())
                            plt.close()
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de la g√©n√©ration du graphique de d√©pendance et interaction : {str(e)}")
                            plt.close()  # S'assurer que la figure est ferm√©e
            else:
                st.warning("‚ö†Ô∏è Les valeurs SHAP ne sont pas disponibles. Veuillez v√©rifier que le mod√®le a √©t√© charg√© correctement.")
        
            # Menu pour afficher les graphiques d'interpr√©tabilit√© locale
            st.markdown("<div class='intro-header'>Interpr√©tabilit√© locale du mod√®le</div>", unsafe_allow_html=True)
        
            # V√©rifier que l'explainer et les valeurs SHAP sont disponibles
            if explainer is not None and shap_values is not None:
                local_shap_choice = st.selectbox("Choisissez un graphique d'interpr√©tabilit√© locale", 
                                                ["Force Plot", "Waterfall Plot", "Decision Plot"])
            
                # S√©lectionner l'index de l'observation du dataframe "X_test"
                observation_index = st.number_input("Indiquez l'index de l'observation dans X_test", 
                                                   min_value=0, max_value=len(st.session_state.X_test)-1, step=1)
        
                if local_shap_choice == "Force Plot":
                    with st.spinner("G√©n√©ration du Force Plot..."):
                        # Pour les mod√®les (CatBoost, XGBoost)
                        try:
                            # Cr√©er un HTML pour le force plot
                            plt.figure(figsize=(10, 3))
                            force_plot = shap.force_plot(
                                base_value=getattr(explainer, 'expected_value', 0),
                                shap_values=shap_values[observation_index],
                                features=st.session_state.X_test.iloc[observation_index],
                                feature_names=feature_names,
                                matplotlib=True,
                                show=False
                            )
                            st.pyplot(plt.gcf())
                            plt.close()
                        except Exception as e:
                            st.error(f"Erreur lors de l'affichage du Force Plot: {str(e)}")
                            st.info("Essai avec une m√©thode alternative...")
                            try:
                                # M√©thode alternative
                                plt.figure(figsize=(10, 3))
                            
                                # Cr√©er un barplot simple au lieu d'un waterfall plot
                                feature_names = st.session_state.X_test.columns.tolist()
                                shap_values_to_plot = shap_values[observation_index]
                            
                                # Trier les valeurs SHAP par importance
                                indices = np.argsort(np.abs(shap_values_to_plot))
                            
                                # Prendre les 10 features les plus importantes
                                top_indices = indices[-10:]
                            
                                # Cr√©er un barplot horizontal
                                plt.barh(
                                    y=np.array(feature_names)[top_indices],
                                    width=shap_values_to_plot[top_indices],
                                    color=['#ff0d57' if x > 0 else '#1E88E5' for x in shap_values_to_plot[top_indices]]
                                )
                            
                                plt.title("Alternative au Force Plot (Top 10 features)", fontsize=12)
                                plt.xlabel("Impact sur la pr√©diction (valeur SHAP)")
                                plt.tight_layout()
                                st.pyplot(plt.gcf())
                                plt.close()
                            except Exception as e2:
                                st.error(f"L'affichage alternatif a √©chou√©: {str(e2)}")
                
                elif local_shap_choice == "Waterfall Plot":
                    with st.spinner("G√©n√©ration du Waterfall Plot..."):
                        # Pour les mod√®les CatBoost et XGBoost
                        try:
                            # Cr√©er un objet Explanation pour le waterfall plot
                            plt.figure(figsize=(10, 6))
                        
                            # Cr√©er un objet Explanation √† partir des valeurs SHAP
                            # Cette approche utilise directement les valeurs brutes pour cr√©er un graphique alternatif
                            feature_names = st.session_state.X_test.columns.tolist()
                            shap_values_to_plot = shap_values[observation_index]
                        
                            # Trier les valeurs SHAP par importance
                            indices = np.argsort(np.abs(shap_values_to_plot))
                        
                            # Prendre les 10 features les plus importantes
                            top_indices = indices[-10:]
                        
                            # Cr√©er un barplot horizontal
                            plt.barh(
                                y=np.array(feature_names)[top_indices],
                                width=shap_values_to_plot[top_indices],
                                color=['#ff0d57' if x > 0 else '#1E88E5' for x in shap_values_to_plot[top_indices]]
                            )
                        
                            plt.title("Waterfall Plot (Top 10 features)", fontsize=12)
                            plt.xlabel("Impact sur la pr√©diction (valeur SHAP)")
                            plt.tight_layout()
                            st.pyplot(plt.gcf())
                            plt.close()
                        
                            # Afficher aussi la valeur de base et la somme des valeurs SHAP
                            expected_value = getattr(explainer, 'expected_value', 0)
                            if isinstance(expected_value, list) or isinstance(expected_value, np.ndarray):
                                expected_value = expected_value[0]
                        
                            st.write(f"Valeur de base (expected value): {float(expected_value):.4f}")
                            st.write(f"Somme des valeurs SHAP: {float(np.sum(shap_values_to_plot)):.4f}")
                            st.write(f"Pr√©diction finale: {float(expected_value + np.sum(shap_values_to_plot)):.4f}")
                        
                        except Exception as e:
                            st.error(f"Erreur lors de l'affichage du Waterfall Plot: {str(e)}")
                        st.info("Essai avec une m√©thode alternative...")
                        try:
                            # M√©thode alternative
                            plt.figure(figsize=(10, 6))
                        
                            # Cr√©er un barplot simple au lieu d'un waterfall plot
                            feature_names = st.session_state.X_test.columns.tolist()
                            shap_values_to_plot = shap_values[observation_index]
                        
                            # Trier les valeurs SHAP par importance
                            indices = np.argsort(np.abs(shap_values_to_plot))
                        
                            # Prendre les 10 features les plus importantes
                            top_indices = indices[-10:]
                        
                            # Cr√©er un barplot horizontal
                            plt.barh(
                                y=np.array(feature_names)[top_indices],
                                width=shap_values_to_plot[top_indices],
                                color=['#ff0d57' if x > 0 else '#1E88E5' for x in shap_values_to_plot[top_indices]]
                            )
                        
                            plt.title("Alternative au Waterfall Plot (Top 10 features)", fontsize=12)
                            plt.xlabel("Impact sur la pr√©diction (valeur SHAP)")
                            plt.tight_layout()
                            st.pyplot(plt.gcf())
                            plt.close()
                        except Exception as e2:
                            st.error(f"L'affichage alternatif a √©chou√©: {str(e2)}")
        
                elif local_shap_choice == "Decision Plot":
                    with st.spinner("G√©n√©ration du Decision Plot..."):
                        # Decision Plot ne peut pas √™tre mis en cache facilement, on l'affiche directement
                    
                        # Pour les mod√®les CatBoost et XGBoost
                        try:
                            plt.figure(figsize=(10, 8))
                            shap.decision_plot(
                                getattr(explainer, 'expected_value', 0),
                                shap_values[observation_index],
                                st.session_state.X_test.iloc[observation_index],
                                feature_names=feature_names,
                                show=False
                            )
                            plt.tight_layout()
                            st.pyplot(plt.gcf())
                        except Exception as e:
                            st.error(f"Erreur lors de l'affichage du Decision Plot: {str(e)}")
                            st.info("Essai avec une m√©thode alternative...")
                            try:
                                # M√©thode alternative
                                plt.figure(figsize=(10, 8))
                                shap.plots.decision(
                                    getattr(explainer, 'expected_value', 0),
                                        shap_values[observation_index],
                                    st.session_state.X_test.iloc[observation_index,:],
                                    feature_names=feature_names,
                                    show=False
                                )
                                plt.tight_layout()
                                st.pyplot(plt.gcf())
                            except Exception as e2:
                                st.error(f"L'affichage du Decision Plot a √©chou√©: {str(e2)}")
            else:
                st.warning("‚ö†Ô∏è L'explainer ou les valeurs SHAP ne sont pas disponibles. Veuillez v√©rifier que le mod√®le a √©t√© charg√© correctement.")
    
        # Nettoyage de la m√©moire √† la fin de la section Mod√©lisation
        try:
            # Nettoyer les variables volumineuses qui ne sont plus n√©cessaires
            if 'shap_values' in locals():
                del shap_values
            if 'explainer' in locals():
                del explainer
            if 'model' in locals():
                del model
        
            # Forcer le garbage collection
            cleanup_memory()
        
            # Nettoyer aussi les figures matplotlib
            import matplotlib.pyplot as plt
            plt.close('all')
        
            # Log m√©moire finale
            log_memory_usage("Fin de la section Mod√©lisation")
        
            # Afficher un message de succ√®s si tout s'est bien pass√©
            final_memory = get_memory_usage()
            if final_memory < 1500:  # Moins de 1.5GB utilis√©
                print(f"‚úÖ Section Mod√©lisation termin√©e avec succ√®s. M√©moire utilis√©e : {final_memory:.0f} MB")
        except Exception as cleanup_error:
            # Ne pas afficher d'erreur pour le nettoyage, juste logger
            print(f"Erreur lors du nettoyage m√©moire : {str(cleanup_error)}")
        
    except MemoryError as e:
        # Gestion sp√©cifique des erreurs de m√©moire
        st.error("‚ùå Erreur de m√©moire insuffisante dans la section Mod√©lisation.")
        st.info("üí° Veuillez recharger la page manuellement ou s√©lectionner moins de donn√©es.")
        cleanup_memory()
        st.stop()
    except Exception as e:
        # Gestion g√©n√©rale des autres erreurs
        st.error(f"‚ùå Une erreur est survenue dans la section Mod√©lisation : {str(e)}")
        st.info("üí° Essayez de recharger la page ou de s√©lectionner un autre mod√®le.")
        print(f"Erreur dans la section Mod√©lisation : {str(e)}")
        cleanup_memory()
        cleanup_memory()

if selected == "Conclusion":  # Conclusion
    # Contenu de la page de conclusion
    
    # Ajout d'un style CSS pour am√©liorer l'apparence (m√™me style que l'introduction)
    st.markdown("""
    <style>
        .main-title {
            color: #1E3A8A;
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 2px solid #3B82F6;
            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        }
        .title-container {
            background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }
        .conclusion-header {
            color: #1E3A8A;
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
        }
        .conclusion-text {
            font-size: 16px;
            line-height: 1.6;
            text-align: justify;
            margin-bottom: 15px;
        }
        .conclusion-highlight {
            background-color: #F3F4F6;
            border-left: 4px solid #3B82F6;
            padding: 15px;
            margin: 20px 0;
        }
        .conclusion-section {
            margin-top: 30px;
            margin-bottom: 30px;
        }
        .conclusion-list {
            margin-left: 20px;
            margin-bottom: 15px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre principal am√©lior√© avec conteneur
    st.markdown("""
    <div class="title-container">
        <div class="main-title">Synth√®se et Perspectives</div>
        <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Interpr√©tabilit√© et implications des r√©sultats</div>
    </div>
    """, unsafe_allow_html=True)
    
    
    # R√©sum√© concis
    st.markdown("""
    <div class="conclusion-text">
        L'analyse SHAP du mod√®le CatBoostClassifier a r√©v√©l√© les facteurs cl√©s influen√ßant la pr√©diction de gravit√© des accidents routiers.
    </div>
    """, unsafe_allow_html=True)

    
    # Variables influentes - Version concise
    st.markdown('<div class="conclusion-header" style="font-size: 24px;">Facteurs d√©terminants</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="conclusion-highlight">
        <ul>
            <li><strong>Cat√©gorie de v√©hicule</strong> : Les v√©hicules l√©gers sont associ√©s √† une diminution de la gravit√©, contrairement aux deux-roues motoris√©s lourds.</li>
            <li><strong>Position de l'usager</strong> : Le r√¥le de conducteur ou passager influence significativement l'issue d'un accident.</li>
            <li><strong>Pr√©sence de pi√©ton</strong> : Facteur majeur augmentant la gravit√© des accidents.</li>
            <li><strong>Type de collision et man≈ìuvre</strong> : Variables d√©terminantes selon les circonstances.</li>
            <li><strong>Facteurs temporels</strong> (jour, mois, heure) : Influence contextuelle sur certains types d'accidents.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown(
        """
        <p></p>
        <p></p>
        """,
            unsafe_allow_html=True
    )
    
    st.markdown("""
    <div class="conclusion-header">
        <div class="conclusion-header" style="font-size: 24px;">Implications pour la s√©curit√© routi√®re</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Utilisation des colonnes Streamlit pour cr√©er un effet de cartes
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style="background-color: white; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); padding: 20px; border-top: 4px solid #3B82F6; height: 300px; margin: 5px;">
            <div style="font-size: 32px; text-align: center; margin-bottom: 15px;">üöó</div>
            <div style="font-weight: 600; color: #1E3A8A; font-size: 18px; text-align: center; margin-bottom: 15px;">V√©hicules vuln√©rables</div>
            <div style="text-align: center; color: #4B5563; font-size: 15px; max-height: 170px; overflow: auto;">N√©cessit√© de mesures sp√©cifiques pour les deux-roues motoris√©s et v√©hicules lourds.</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="background-color: white; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); padding: 20px; border-top: 4px solid #3B82F6; height: 300px; margin: 5px;">
            <div style="font-size: 32px; text-align: center; margin-bottom: 15px;">üö∂</div>
            <div style="font-weight: 600; color: #1E3A8A; font-size: 18px; text-align: center; margin-bottom: 15px;">Protection des pi√©tons</div>
            <div style="text-align: center; color: #4B5563; font-size: 15px; max-height: 170px; overflow: auto;">Priorit√© d'action pour ces usagers particuli√®rement vuln√©rables.</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="background-color: white; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); padding: 20px; border-top: 4px solid #3B82F6; height: 300px; margin: 5px;">
            <div style="font-size: 32px; text-align: center; margin-bottom: 15px;">üîÑ</div>
            <div style="font-weight: 600; color: #1E3A8A; font-size: 18px; text-align: center; margin-bottom: 15px;">Approche syst√©mique</div>
            <div style="text-align: center; color: #4B5563; font-size: 15px; max-height: 170px; overflow: auto;">Combinaison d'am√©liorations d'infrastructures et de sensibilisation des conducteurs.</div>
        </div>
        """, unsafe_allow_html=True)


########################################################################################
if selected == "Chat":
    # Ajout d'un style CSS pour am√©liorer l'apparence (m√™me style que les autres pages)
    st.markdown("""
    <style>
        .main-title {
            color: #1E3A8A;
            font-size: 36px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 2px solid #3B82F6;
            text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
        }
        .title-container {
            background: linear-gradient(to right, #f0f4ff, #ffffff, #f0f4ff);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        }
        .chat-header {
            color: #1E3A8A;
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 20px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Titre principal am√©lior√© avec conteneur
    st.markdown("""
    <div class="title-container">
        <div class="main-title">Chat Pr√©dictif</div>
        <div style="text-align: center; font-size: 20px; color: #4B5563; font-weight: 500;">Pr√©diction de la gravit√© des accidents par description textuelle</div>
    </div>
    """, unsafe_allow_html=True)

    # Fonction cach√©e pour charger le mod√®le une seule fois
    @st.cache_resource
    def load_chat_model():
        MODELE_PATH = "./models/20250129_catboost_best_model.pkl"
        return joblib.load(MODELE_PATH)
    
    # Chargement du mod√®le avec cache
    model = load_chat_model()

    # Fonction pour pr√©dire la gravit√© de l'accident
    def predire_gravite(description: str):
        """Prend en entr√©e une description textuelle et pr√©dit la gravit√© de l'accident."""
        # Convertir la description en une repr√©sentation adapt√©e au mod√®le
        # Cette √©tape d√©pend de votre preprocessing (TF-IDF, embeddings, etc.)
        # Pour l'exemple, nous allons juste retourner une pr√©diction al√©atoire
        # Note: description parameter will be used when the actual model preprocessing is implemented
        _ = description  # Mark as intentionally unused for now
        import random
        predictions = ["Indemne", "Bless√© l√©ger", "Bless√© hospitalis√©", "Tu√©"]
        return random.choice(predictions)

    # Suppression du titre simple et remplacement par une instruction plus claire
    st.markdown('<div class="chat-header">Entrez une description d\'accident pour obtenir une pr√©diction</div>', unsafe_allow_html=True)
    st.write("Notre mod√®le analysera votre description et pr√©dira la gravit√© probable de l'accident.")

    # Zone de chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Affichage des messages pr√©c√©dents
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    # Entr√©e utilisateur
    prompt = st.chat_input("D√©crivez l'accident...")

    if prompt:
        # Ajouter le message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        # Obtenir la pr√©diction du mod√®le
        prediction = predire_gravite(prompt)

        # Ajouter la r√©ponse du mod√®le
        with st.chat_message("assistant"):
            response = f"Selon notre analyse, la gravit√© de cet accident est estim√©e comme : **{prediction}**"
            st.write(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

# Ajout d'un encadr√© en bas de page avec des liens
# Cette section sera affich√©e sur toutes les pages de l'application
st.markdown("<hr>", unsafe_allow_html=True)

# Style CSS pour l'encadr√© footer
st.markdown("""
<style>
    .footer-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 15px;
        margin-top: 30px;
        margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        text-align: center;
    }
    .footer-title {
        font-size: 16px;
        font-weight: 600;
        color: #1E3A8A;
        margin-bottom: 10px;
    }
    .footer-links {
        display: flex;
        justify-content: center;
        flex-wrap: wrap;
        gap: 20px;
        margin-bottom: 10px;
    }
    .footer-link {
        display: inline-flex;
        align-items: center;
        color: #3B82F6;
        text-decoration: none;
        font-weight: 500;
        transition: color 0.2s;
    }
    .footer-link:hover {
        color: #1E3A8A;
        text-decoration: underline;
    }
    .footer-icon {
        margin-right: 5px;
        font-size: 20px;
    }
</style>
""", unsafe_allow_html=True)

# Contenu de l'encadr√©
st.markdown("""
<div class="footer-container">
    <div class="footer-title">Projet r√©alis√© et publi√© par</div>
    <div class="footer-links">
        <a href="https://www.linkedin.com/in/selina-balikel-292038220/" class="footer-link" target="_blank">
            <span class="footer-icon">üë§</span> Selina BALIKEL
        </a>
        <a href="https://www.linkedin.com/in/ahmed-hammoumi-86766a1/" class="footer-link" target="_blank">
            <span class="footer-icon">üë§</span> Ahmed HAMMOUMI
        </a>
        <a href="https://www.linkedin.com/in/ndiaye-bacar-b92aa555/" class="footer-link" target="_blank">
            <span class="footer-icon">üë§</span> Bacar NDIAYE
        </a>
        <a href="https://github.com/selinablkl/st_Accident" class="footer-link" target="_blank">
            <span class="footer-icon">üíª</span> GitHub Repository
        </a>
    </div>
    <div style="font-size: 12px; color: #6B7280;">¬© 2024 - Analyse des Accidents Routiers</div>
</div>
""", unsafe_allow_html=True)